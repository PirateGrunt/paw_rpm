{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pPVhJe1M1ZG"
   },
   "source": [
    "# US Hurricane Catastrophe Model\n",
    "\n",
    "A very simple model of US hurricane exposure parameterized to observed event frequency 1851-2017 and a smattering of losses 1970-2017.\n",
    "\n",
    "* Frequency: Poisson(1.74)\n",
    "* Severity: lognormal($\\mu=19.595, \\sigma=2.581$)\n",
    "\n",
    "## Model Algorithm I \n",
    "\n",
    "    for year = 1 to N\n",
    "        simulate number of events E from Poisson(1.74)\n",
    "        for event_num = 1 to E\n",
    "            simulate loss L from Lognormal(mu, sigma)\n",
    "            store year, event_num, L\n",
    "\n",
    "## Model Algorithm II \n",
    "\n",
    "This method is more suited to a spreadsheet implementation. \n",
    "\n",
    "    time = 0\n",
    "    event_id = 0\n",
    "    last_year = 0\n",
    "    for event = 1 to N\n",
    "        simulate waiting time for event t from Exponential(1.74)\n",
    "        time = time + t\n",
    "        year = integer part of time\n",
    "        if year > last_year then event_id = 0, last_year = year\n",
    "        simulate loss L from Lognormal(mu, sigma)\n",
    "        store year, event_id, L\n",
    "        event_id = event_id + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-EHaF14--kx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(context='paper', style='darkgrid', font='sans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omR7vzyQMtHn"
   },
   "source": [
    "## Claim Count Component\n",
    "\n",
    "Based on an analysis of landfalling hurricanes since 1851 we selected a Poisson(1.74) to model the number of hurricanes making landfall in the Continental US each year. \n",
    "\n",
    "The next few commands create a variable to represent this random variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjHzweX5_Cbq"
   },
   "outputs": [],
   "source": [
    "freq = 290 / 167\n",
    "poi = ss.poisson(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HbRa2YIo_F5e",
    "outputId": "2fee81b3-baac-47bf-b413-7034e93814cb"
   },
   "outputs": [],
   "source": [
    "# simulate 10 random draws\n",
    "poi.rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "UFQ5TNaE_Kg1",
    "outputId": "25a5a890-199a-4e8d-e5fd-09daeaa6a71f"
   },
   "outputs": [],
   "source": [
    "# generate 100,000 draws and creates a histogram\n",
    "N = 100000\n",
    "temp = poi.rvs(N)\n",
    "plt.hist(temp, bins=np.arange(12), density=True)\n",
    "plt.title('Histogram of Model Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CVHPzMifZ-gH",
    "outputId": "65afc7ae-dff0-4f63-9e78-4352e783f964"
   },
   "outputs": [],
   "source": [
    "# can compute frequencies by hand \n",
    "unq = np.unique(temp, return_counts=True)\n",
    "unq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4Z0TQVA_Ngm"
   },
   "outputs": [],
   "source": [
    "# can compare with actual \n",
    "model = [np.exp(-freq)]\n",
    "for i in range(1,len(unq[0])):\n",
    "    model.append(model[i-1] * freq / i)\n",
    "model = np.array(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "YnXmuROvcUwb",
    "outputId": "7410e371-61ff-4b27-af17-b37b768546e4"
   },
   "outputs": [],
   "source": [
    "# compare with freqs\n",
    "print('    N Simulation           Model         Error')\n",
    "for i, s, m in zip(unq[0], unq[1], N*model):\n",
    "    print(f'{i:5d}\\t{s:8,d}\\t{m:8,.1f}\\t{s/m-1:6.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "bpxr_5C9F1Jr",
    "outputId": "1ea53ec5-79f9-40b4-aec7-20b91098e1b5"
   },
   "outputs": [],
   "source": [
    "# or the same thing using pandas\n",
    "df = pd.DataFrame(dict(N=unq[0], Simulation=unq[1]/N, Model=model))\n",
    "df['Error'] = df.Simulation / df.Model - 1\n",
    "df = df.set_index(\"N\")\n",
    "df.index.name=\"N\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "2yzSmuZ6GgjK",
    "outputId": "3676134f-ad06-4861-9581-dc75abacb144"
   },
   "outputs": [],
   "source": [
    "df[['Model', 'Simulation']].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['Model', 'Simulation']].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTmKt3DYM7kp"
   },
   "source": [
    "## Severity Component\n",
    "\n",
    "Lognormal(mu, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9u2vwfRUM8sj"
   },
   "outputs": [],
   "source": [
    "mu = 19.595\n",
    "sigma = 2.581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMGPA_A_M9Za"
   },
   "outputs": [],
   "source": [
    "# variable to simulate lognormals\n",
    "ln = ss.lognorm(sigma, scale=np.exp(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hIfhY0QydmY4",
    "outputId": "211100ac-1537-449d-9585-05984fca61d2"
   },
   "outputs": [],
   "source": [
    "# mean and variance\n",
    "ln.stats('mv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkJ4UWT4NvRK"
   },
   "outputs": [],
   "source": [
    "sample = ln.rvs(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9M5lSaPMNx1r",
    "outputId": "8f992f28-242d-4170-bd06-5107f0cbbea4"
   },
   "outputs": [],
   "source": [
    "# compare sample mean with known mean of lognormal\n",
    "np.array((sample.mean(), np.exp(mu + sigma**2 / 2), ln.stats('m'))) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "wz5l9f7LNvTa",
    "outputId": "8e82b811-54b5-42bb-f3d0-38a0ff9d669d"
   },
   "outputs": [],
   "source": [
    "# histogram of log losses \n",
    "plt.hist(np.log(sample), density=True, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "colab_type": "code",
    "id": "opxRKsN2NvVq",
    "outputId": "b0c0a004-3927-4ebd-ecb6-130595de06c8"
   },
   "outputs": [],
   "source": [
    "# probability plot = perfect\n",
    "ss.probplot(np.log(sample), plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beAvmigMM9sL"
   },
   "source": [
    "# Aggregate Losses\n",
    "\n",
    "## Model Algorithm I \n",
    "\n",
    "    for year = 1 to N\n",
    "        simulate number of events E from Poisson(1.74)\n",
    "        for event_num = 1 to E\n",
    "            simulate loss L from Lognormal(mu, sigma)\n",
    "            store year, event_num, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVAg7AHuM_Ea"
   },
   "outputs": [],
   "source": [
    "# setup  variables \n",
    "# N = number of simulation years\n",
    "N = 100000\n",
    "freq = 290 / 167\n",
    "freq_dist = ss.poisson(freq)\n",
    "mu = 19.595\n",
    "sigma = 2.581\n",
    "sev_dist = ss.lognorm(sigma, scale=np.exp(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kozdVtVQcGej",
    "outputId": "b37f72b6-ef8e-4fde-a1a4-ccf3bc65b295"
   },
   "outputs": [],
   "source": [
    "# simulate annual event founds \n",
    "event_counts = freq_dist.rvs(N)\n",
    "num_events = event_counts.sum()\n",
    "num_events, N * freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLI_kaU4fVyR"
   },
   "source": [
    "## ELT and YLT\n",
    "\n",
    "Event Loss Table, ELT, will have columns\n",
    "\n",
    "* Event ID\n",
    "* Simulated Year\n",
    "* Event Loss\n",
    "\n",
    "Yearly Loss Table, YLT, will have columns \n",
    "\n",
    "* Year\n",
    "* Event count, the number of events in the year\n",
    "* Sum = total loss in the year (for Agg PMLs)\n",
    "* Max = largest loss in the year (for occ PMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EH9PspnBeyw9"
   },
   "outputs": [],
   "source": [
    "# container for YLT\n",
    "ylt = np.zeros((N, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUEgOqN7ez6x"
   },
   "outputs": [],
   "source": [
    "# fill in year ID and event count, arrays are 0 based\n",
    "ylt[:, 0] = np.arange(N)\n",
    "ylt[:, 1] = event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "KMjxSWNofqhd",
    "outputId": "5905f9c5-c7b4-49a5-fa40-2b11d794dc1f"
   },
   "outputs": [],
   "source": [
    "# look at the top ten rows (:10) and all columns (:)\n",
    "ylt[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YSufDL2frld"
   },
   "outputs": [],
   "source": [
    "# container for ELT, now we know number of rows - sum of num events from YLT\n",
    "elt = np.zeros((num_events, 3))\n",
    "# add event ID, counter 0, 1, ...\n",
    "elt[:, 0] = np.arange(num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l72kHw_If8RT",
    "outputId": "3aa8d2c7-9769-4704-d6d3-359d75b47ea1"
   },
   "outputs": [],
   "source": [
    "# how big is ylt: should be freq x N rows, can use shape or len:\n",
    "elt.shape,  len(elt), freq * N, freq, num_events, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNVbcBwHf9Ll"
   },
   "outputs": [],
   "source": [
    "# simulate individual event losses\n",
    "elt[:, 2] = sev_dist.rvs(num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "c2OqXVnrlnZG",
    "outputId": "5d828bf0-2cbf-48a3-fb69-916512c81507"
   },
   "outputs": [],
   "source": [
    "# look at answer\n",
    "elt[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfHO4QyAgRdw"
   },
   "outputs": [],
   "source": [
    "# tricky part...need to fill in the event years in the YLT\n",
    "# make an array showing starting and ending number of events for each year\n",
    "event_boundaries = event_counts.cumsum()\n",
    "# start at zero\n",
    "event_boundaries = np.hstack((0, event_boundaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2iVWnsfinbhQ",
    "outputId": "3de20e7e-0dd6-43c2-e018-7d95a151b952"
   },
   "outputs": [],
   "source": [
    "ylt[:10, 1], event_boundaries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kKqaAsPikVu"
   },
   "outputs": [],
   "source": [
    "# non pythonic \n",
    "%%timeit \n",
    "for i in range(N):\n",
    "    if event_boundaries[i] < event_boundaries[i+1]:\n",
    "        elt[event_boundaries[i]:event_boundaries[i+1], 1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "OqrgtVj7lqgl",
    "outputId": "6bee4550-b383-40b8-8ebd-8cf2357d5cc4"
   },
   "outputs": [],
   "source": [
    "# num events per year and the created year IDs\n",
    "ylt[:10,1], elt[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FwUy6xWgiaD"
   },
   "outputs": [],
   "source": [
    "# maybe more pythonic\n",
    "# %%timeit\n",
    "for i, (b, e) in enumerate(zip(event_boundaries[:-1], event_boundaries[1:])):\n",
    "    if e > b:\n",
    "        elt[b:e, 1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "_lXjKBX_g4bf",
    "outputId": "49072649-72a8-45da-ebf0-b992376ffcd6"
   },
   "outputs": [],
   "source": [
    "# top 10 rows of ylt and elt\n",
    "ylt[:10, :], elt[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fFMj8ycNhgy1",
    "outputId": "243bb28d-a710-41d2-81d9-4b70a61bafbc"
   },
   "outputs": [],
   "source": [
    "# combine: add losses to ELT and summarize back to the YLT, non pythonic\n",
    "# %%timeit\n",
    "for i in range(N-1):\n",
    "    if event_boundaries[i] < event_boundaries[i+1]:\n",
    "        elt[event_boundaries[i]:event_boundaries[i+1], 1] = i\n",
    "        ylt[i, 2] = elt[event_boundaries[i]:event_boundaries[i+1], 2].sum()\n",
    "        ylt[i, 3] = elt[event_boundaries[i]:event_boundaries[i+1], 2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "sv381pvDpG-0",
    "outputId": "ea8c7509-6e39-4174-aab0-d5e7bc866eac"
   },
   "outputs": [],
   "source": [
    "# top 10 rows of ylt and elt\n",
    "ylt[:10, :], elt[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baeLfRJkhotA"
   },
   "outputs": [],
   "source": [
    "# combine: add losses to ELT and summarize back to the YLT, pythonic\n",
    "# %%timeit\n",
    "for i, (b, e) in enumerate(zip(event_boundaries[:-1], event_boundaries[1:])):\n",
    "    if e > b:\n",
    "        elt[b:e, 1] = i\n",
    "        ylt[i, 2] = elt[b:e, 2].sum()\n",
    "        ylt[i, 3] = elt[b:e, 2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OA3gCK6opx5"
   },
   "outputs": [],
   "source": [
    "# top 10 rows of ylt and elt\n",
    "ylt[:10, :], elt[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "876Tb5U4tUKV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rX3NHRJ9tU1P"
   },
   "source": [
    "### Use data types and name columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdpxlmxSsqPF"
   },
   "outputs": [],
   "source": [
    "def simulate1(N, freq, mu, sigma):\n",
    "    \"\"\"\n",
    "    Simulate ELT and YLT with N years, Poisson(freq) and lognormal(mu, sigma)\n",
    "    severity\n",
    "    \n",
    "    \"\"\"\n",
    "    freq_dist = ss.poisson(freq)\n",
    "    sev_dist = ss.lognorm(sigma, scale=np.exp(mu))\n",
    "\n",
    "    # simulate events per year, figure number of events \n",
    "    event_counts = freq_dist.rvs(N)\n",
    "    num_events = event_counts.sum()\n",
    "    num_events, N * freq\n",
    "    \n",
    "    # make YLT\n",
    "    ylt = np.zeros(N, dtype=[('year_id', 'int32'), ('num_events', 'int32'), \n",
    "                         ('sum_loss', 'float64'), \n",
    "                         ('max_loss', 'float64')])\n",
    "    \n",
    "    # fill in year ID and event count, arrays are 0 based\n",
    "    ylt['year_id'] = np.arange(N)\n",
    "    ylt['num_events'] = event_counts\n",
    "    \n",
    "    # container for ELT, now we know number of rows - sum of num events from YLT\n",
    "    elt = np.zeros(num_events, dtype=[('event_id', 'int32'), ('year_id', 'int32'), \n",
    "                         ('loss', 'float64')])\n",
    "    # add event ID, counter 0, 1, ...\n",
    "    elt['event_id'] = np.arange(num_events)\n",
    "       \n",
    "    event_boundaries = event_counts.cumsum()\n",
    "    event_boundaries = np.hstack((0, event_boundaries))\n",
    "    elt['loss'] = sev_dist.rvs(num_events)\n",
    "    \n",
    "    # combine: add losses to ELT and summarize back to the YLT, non pythonic\n",
    "    for i in range(N-1):\n",
    "        if event_boundaries[i] < event_boundaries[i+1]:\n",
    "            elt[event_boundaries[i]:event_boundaries[i+1]]['year_id'] = i\n",
    "            ylt[i]['sum_loss'] = elt[event_boundaries[i]:event_boundaries[i+1]]['loss'].sum()\n",
    "            ylt[i]['max_loss'] = elt[event_boundaries[i]:event_boundaries[i+1]]['loss'].max()\n",
    "            \n",
    "    # sort YLT by loss \n",
    "    ylt.sort(order='sum_loss')\n",
    "    \n",
    "    # return answer\n",
    "    return elt, ylt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hgULUh1uzC9"
   },
   "outputs": [],
   "source": [
    "%timeit elt, ylt = simulate1(100000, 290/167, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2eAaYuyv4vw"
   },
   "outputs": [],
   "source": [
    "def simulate2(N, freq, mu, sigma):\n",
    "    \"\"\"\n",
    "    Simulate ELT and YLT with N years, Poisson(freq) and lognormal(mu, sigma)\n",
    "    severity. Alternative aggregation to YLT.\n",
    "\n",
    "    \"\"\"\n",
    "    freq_dist = ss.poisson(freq)\n",
    "    sev_dist = ss.lognorm(sigma, scale=np.exp(mu))\n",
    "\n",
    "    # simulate events per year, figure number of events \n",
    "    event_counts = freq_dist.rvs(N)\n",
    "    num_events = event_counts.sum()\n",
    "    num_events, N * freq\n",
    "    \n",
    "    # make YLT\n",
    "    ylt = np.zeros(N, dtype=[('year_id', 'int32'), ('num_events', 'int32'), \n",
    "                         ('sum_loss', 'float64'), \n",
    "                         ('max_loss', 'float64')])\n",
    "   \n",
    "    # fill in year ID and event count, arrays are 0 based\n",
    "    ylt['year_id'] = np.arange(N)\n",
    "    ylt['num_events'] = event_counts\n",
    "    \n",
    "    # container for ELT, now we know number of rows - sum of num events from YLT\n",
    "    elt = np.zeros(num_events, dtype=[('event_id', 'int32'), ('year_id', 'int32'), \n",
    "                         ('loss', 'float64')])\n",
    "    # add event ID, counter 0, 1, ...\n",
    "    elt['event_id'] = np.arange(num_events)\n",
    "    \n",
    "    \n",
    "    event_boundaries = event_counts.cumsum()\n",
    "    event_boundaries = np.hstack((0, event_boundaries))\n",
    "    elt['loss'] = sev_dist.rvs(num_events)\n",
    "    \n",
    "    # combine: add losses to ELT and summarize back to the YLT, non pythonic\n",
    "    for i in range(N-1):\n",
    "        if event_boundaries[i] < event_boundaries[i+1]:\n",
    "            temp = elt[event_boundaries[i]:event_boundaries[i+1]]\n",
    "            temp['year_id'] = i\n",
    "            ylt[i]['sum_loss'] = temp['loss'].sum()\n",
    "            ylt[i]['max_loss'] = temp['loss'].max()\n",
    "            \n",
    "    # sort YLT by loss \n",
    "    ylt.sort(order='sum_loss')\n",
    "    \n",
    "    # return answer\n",
    "    return elt, ylt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqERayVEx9xW"
   },
   "outputs": [],
   "source": [
    "%timeit elt, ylt = simulate2(100000, 290/167, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXDrdC2xx_LK"
   },
   "outputs": [],
   "source": [
    "def simulate3(num_events, freq, mu, sigma):\n",
    "    \"\"\"\n",
    "    Simulate ELT and YLT with num_events events, Poisson(freq) and lognormal(mu, sigma)\n",
    "    severity. Method II exponential waiting time approach. Use Pandas.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    freq_dist = ss.poisson(freq)\n",
    "    sev_dist = ss.lognorm(sigma, scale=np.exp(mu))\n",
    "\n",
    "    # simulate event years\n",
    "    e = ss.expon(scale=1/freq)\n",
    "    event_times = np.array(e.rvs(num_events).cumsum(), dtype=int)\n",
    "    N = event_times[-1]\n",
    "\n",
    "    # container for ELT, given number of rows \n",
    "    elt = np.zeros(num_events, dtype=[('event_id', 'int32'), ('year_id', 'int32'), \n",
    "                         ('loss', 'float64')])\n",
    "    elt = pd.DataFrame(elt)\n",
    "    # add event ID, counter 0, 1, ...\n",
    "    elt['event_id'] = np.arange(num_events)\n",
    "    elt['year_id'] = event_times\n",
    "    elt['loss'] = sev_dist.rvs(num_events)\n",
    "    elt = elt.set_index('event_id')\n",
    "    \n",
    "    # make YLT\n",
    "    ylt = np.zeros(N, dtype=[('year_id', 'int32'), ('num_events', 'int32'), \n",
    "                         ('sum_loss', 'float64'), \n",
    "                         ('max_loss', 'float64')])\n",
    "    ylt = pd.DataFrame(ylt)\n",
    "    # fill in year ID and event count, arrays are 0 based\n",
    "    ylt['year_id'] = np.arange(N)\n",
    "    ylt = ylt.set_index('year_id')\n",
    "    \n",
    "    g = elt.groupby('year_id')['loss'].agg([np.sum, np.max, np.size])   \n",
    "    ylt['sum_loss'] = g['sum']\n",
    "    ylt['max_loss'] = g['amax']\n",
    "    ylt['num_events'] = g['size']\n",
    "    ylt = ylt.fillna(0)\n",
    "    \n",
    "    # sort YLT by loss \n",
    "    ylt = ylt.sort_values('sum_loss', ascending=False)\n",
    "    \n",
    "    # return answer\n",
    "    return elt, ylt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYHeNB8OJNYh"
   },
   "outputs": [],
   "source": [
    "%timeit elt, ylt = simulate3(100000, 290/167, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1_FyhYULcjO"
   },
   "outputs": [],
   "source": [
    "elt, ylt = simulate3(100000, 290/167, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OC57NOQPMxt8"
   },
   "outputs": [],
   "source": [
    "ylt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H77e61dOUxMC"
   },
   "outputs": [],
   "source": [
    "ylt[['sum_loss', 'max_loss']].reset_index(drop=True).plot(logy=True, subplots=True, figsize=(6,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cAkuvCvVZUz"
   },
   "outputs": [],
   "source": [
    "plt.hist( np.log(ylt.max_loss / ylt.sum_loss), bins=100 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CatModel1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
