{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas = **PAN**el **DA**ta**S**ets\n",
    "\n",
    "\n",
    ">  *pandas* provides high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "* General purpose data munger and ```numpy``` array wrapper  \n",
    "* Persist to / read from variety of data sources including Excel \n",
    "* Two core data structures: a ```Series``` for 1d data and a ```DataFrame``` for 2d data\n",
    "* ```DataFrames``` are indexed by rows and columns and all operations are index-aware\n",
    "* Joins/merge\n",
    "* Summarize, transform\n",
    "* melt, stack/unstack, pivot tables\n",
    "* Excellent time series support \n",
    "* Good integration with Jupyter for viewing data \n",
    "* Graceful handling of missing values \n",
    "* Nice integration with Python string handling \n",
    "* Plotting\n",
    "\n",
    "See [10 minute intro to pandas](http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html).\n",
    "\n",
    "## Functions We Will Discuss\n",
    "\n",
    "* DataFrame\n",
    "* head, tail, describe\n",
    "* unique, value_counts\n",
    "* read_csv\n",
    "* loc, slices, xs\n",
    "* create_index, reset_index \n",
    "* MultiIndex \n",
    "* query \n",
    "* pivot, stack and unstack\n",
    "* **concat**, append, keys \n",
    "* pivot_table (crosstab), pivot \n",
    "* **merge** (indicator) and join\n",
    "* groupby (.groups, .get_group, as_index)\n",
    "* sum, mean, std etc. \n",
    "* aggregate\n",
    "* transform (same size as input whiten)\n",
    "* apply\n",
    "* assign \n",
    "* plot\n",
    "\n",
    "## Functions not covered but check out on your own\n",
    "* map (series), applymap (dataframes) \n",
    "* from_dict\n",
    "* rename \n",
    "* melt\n",
    "* evaluate \n",
    "* str\n",
    "* dt\n",
    "* style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn Plotting \n",
    "\n",
    "```pandas``` + ```seaborn``` $\\approx$ ```tibbles``` + ```ggplot```\n",
    "\n",
    "* relplot  = relational plots, line, scatter \n",
    "* catplot = scatter plot with categorical, box, swarm, bar, count \n",
    "* jointplot, pairplot, distplot, kdeplot\n",
    "* lmplot, regplot, residplot \n",
    "* heatmap, clustermap \n",
    "* faceting, row/column plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# the basics \n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import re\n",
    "\n",
    "# nice printing of dataframes \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# other setup \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "np.set_printoptions(linewidth =  160)\n",
    "\n",
    "# handy utility \n",
    "import textwrap \n",
    "def wdid(ob, ex=False):\n",
    "    ''' what does object do? \n",
    "    '''\n",
    "    print('\\n'.join(textwrap.wrap(' '.join([i for i in dir(ob) if i[0] != '_']), 80)))\n",
    "    if ex:\n",
    "    # optional pause for something more advanced... \n",
    "        for m in [ i for i in dir(np) if i[0] >= 'a' and i[0]<='z']:\n",
    "            print(f'\\n\\n{m}\\n{\"=\"*len(m)}\\n')\n",
    "            print(np.__getattribute__(m).__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pandas DataFrame Creation and Manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create from ```numpy``` array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(5,5); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(x)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.columns = list('abcde')\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acess a column like a dictionary (as elements)\n",
    "df0['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or as attributes if name does not have spaces nor clashes with functions \n",
    "df0.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns \n",
    "# strings in python are unicode \n",
    "df0['id'] = list('αβγδϵ')\n",
    "df0['region'] = ['East', 'North', 'South', 'South', 'West']\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frills\n",
    "df1 = df0.set_index('id')\n",
    "df1.columns.name = 'quantity'\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create from dictionary \n",
    "\n",
    "Entries in dictionary correspond to columns by default. Somewhat analogous to ```mutate```. See also ```assign```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'region': ['East']*3 + ['South', 'West'], \n",
    "                   'type': ['Urban', 'Suburban', 'Rural', 'Rural', 'Urban'], \n",
    "                   'a': np.random.randn(5) * 100, \n",
    "                   'b': np.arange(10,15),\n",
    "                   'c': np.arange(5, dtype=np.float)}, \n",
    "                  index=pd.Index(list('βγδϵω'), name='id'))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat( (df1, df2), sort=True) \n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3v = pd.concat( (df1, df2), sort=True, axis=1) \n",
    "df3v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('/temp/foo.xlsx', sheet_name='Test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(\"/temp/foo.xlsx\", 'Test1', index_col=0, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 / df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1.select_dtypes(np.number))\n",
    "df2.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(np.number) / df2.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sina'] = np.sin(df1.a)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['$\\int_0^2 e^{-a^2/2}da$'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1['$\\int_0^2 e^{-a^2/2}da$']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat((df1,df2), sort=True, keys=['df1', 'df2'], names=['src'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['df1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[:, 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['a', 'b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[:, 'a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.a < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3.a < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.query( ' a < 0 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['df1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['β']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), 'β'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), slice('β','δ')), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), 'b')], df3.loc[:, 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.xs('β', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.xs('b', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer valued loc using row and columns, zero based!\n",
    "df3.iloc[0:2, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.reset_index()  # can also reset just one level; can optionally drop, i.e. not create column \n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['idx'] = df4.src + df4.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot(index='idx', columns='region', values='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot(index=['src', 'id'], columns='region', values=['a', 'sina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot_table(index=['src', 'id'], columns='region', values=['a', 'sina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = df4.groupby(by='src') \n",
    "# to group by index use level="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.get_group('df1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[g4.groups['df1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.agg([sum, np.std, np.min, np.max, np.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.agg({'a' : [sum, np.std, np.min, np.max, np.size], 'b': [sum, np.std] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_funs =  [sum, np.std, np.min, np.max, np.size]\n",
    "g4.agg({'a' : agg_funs, 'b': agg_funs[:2] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.apply(lambda x : display(x))\n",
    "# notice first group printed twice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = g4.apply(lambda x : (x.a * x.b).cumsum())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[:, 'calc'] = x.reset_index(drop=True)  # or x.values, the issue is with the index \n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = g4.get_group('df2')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series( (y.a * y.b).values, name='ab', index=range(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.apply( lambda y : (y.a * y.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.apply( lambda y : pd.Series((y.a * y.b).values))\n",
    "# note the index drives the difference - here we have removed the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.apply( lambda y : pd.DataFrame({'a': y.a.values, 'b': y.b.values,  'ab': (y.a * y.b).values, \n",
    "                                   'sb': y.b.cumsum(), 'db' : y.b.diff() }) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manipulating Triangle Data in Pandas 1: WC Triangles  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Data and Basic Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cas = pd.read_csv(r'http://www.casact.org/research/reserve_data/wkcomp_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas.head()  # cas.tail(), cas.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exerciess\n",
    "\n",
    "1. List the unique companies in the database\n",
    "1. Add a column for loss ratio (IncurLoss_D to EarnedPremNet_D) \n",
    "1. Create a table rows = companies, columns = loss ratio for the ultimate (DevelopmentLag==10) evaluation. Remember ?pd.pivot to get help on a function \n",
    "1. Create a dataframe showing company and total premium and incurred loss (IncurLoss_D to EarnedPremNet_D) over all 10 years for the most recent evaluation. Add loss ratio column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas.GRNAME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas['LR'] = cas.IncurLoss_D / cas.EarnedPremNet_D\n",
    "cas.query('DevelopmentLag == 10').pivot(index='GRNAME', columns='AccidentYear', values='LR').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas.query('DevelopmentLag == 10').replace([-np.inf, np.inf], np.nan).pivot(columns='GRNAME', index='AccidentYear', values='LR').plot(kind='line', legend=False, ylim=[0,3], alpha=0.1, color='blue')\n",
    "cas.query('DevelopmentLag == 10').replace([-np.inf, np.inf], np.nan).groupby('AccidentYear')['LR'].mean().plot(color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cas.query(' AccidentYear + DevelopmentLag == 1998 ').groupby('AccidentYear').agg({'IncurLoss_D' : sum, 'EarnedPremNet_D' : sum})\n",
    "r['LR'] = r.iloc[:, 0] / r.iloc[:, 1]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make the pandas dataframe look more triangle like\n",
    "triangle_frame = cas.query(' DevelopmentYear <= 1997 ').pivot_table(values='CumPaidLoss_D', \n",
    "                                                                    index=['GRNAME','AccidentYear'],\n",
    "                                                                    columns='DevelopmentLag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of zero triangles using filter \n",
    "triangle_frame = triangle_frame.groupby(level=0).filter(lambda x : np.nansum(x)  > 0)\n",
    "triangle_frame.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can filter out smaller triangles too...based on total loss volume of triangle \n",
    "triangle_frame.groupby(level=0).filter(lambda x : x.sum().sum()  > 100000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[-10:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Age-to-age factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[-10:, 1:] / triangle_frame.iloc[-10:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[-10:, 1:].values / triangle_frame.iloc[-10:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best of both worlds \n",
    "triangle_frame.iloc[-10:, 1:].values / triangle_frame.iloc[-10:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ata_df = triangle_frame.iloc[:, 1:].values / triangle_frame.iloc[:, :-1]\n",
    "ata_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDFs and CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df = ata_df.groupby(level=0).mean().fillna(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdfs need cumulative product in reverse...easy to reverse and re-reverse, axis=1 for columns \n",
    "cdf_df = ldf_df.iloc[:, ::-1].cumprod(axis=1).iloc[:, ::-1]\n",
    "cdf_df[10] = 1.\n",
    "cdf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ultimates and IBNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling off the diagonal is a bit tricky \n",
    "diag_df = triangle_frame.groupby(level=0).apply(lambda x : pd.Series(np.diagonal(x.values[:, ::-1])[::-1], index=range(1,11)))\n",
    "diag_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "triangle_frame.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ult_df = (diag_df * cdf_df).fillna(0)\n",
    "ibnr_df = ult_df - diag_df\n",
    "ult_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The business questions answered by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibnr by year \n",
    "ibnr_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr_df.columns = pd.RangeIndex(1988, 1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr_df.replace(np.inf, np.nan).sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 cos for ibnr\n",
    "ibnr_df.replace(np.inf, np.nan).sum(axis=1).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively  \n",
    "ibnr_df.replace(np.inf, np.nan).sum(axis=1).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest 12:ult cdf\n",
    "cdf_df.loc[cdf_df.loc[:, 1] < np.inf, 1].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest 12:24 ldf\n",
    "ldf_df.loc[:, 2].nsmallest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% confidence intervals for each cdf\n",
    "cdf_df.replace(np.inf, np.nan).describe([0.025, 0.975]).loc[['count', '2.5%', 'mean', '97.5%'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Compared to Pandas: Code and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from clean slate...this code will be common \n",
    "triangle_frame = cas.query(' DevelopmentYear <= 1997 ').pivot_table(values='CumPaidLoss_D', \n",
    "                                                                    index=['GRNAME','AccidentYear'],\n",
    "                                                                    columns='DevelopmentLag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def develop_np(triangle_frame):\n",
    "    '''\n",
    "    create latest ldfs, cdfs, diagonal, ultimate and ibnr ndarrays from\n",
    "    input pandas dataframe:\n",
    "    \n",
    "        pd.pivot_table(cas[cas['DevelopmentYear']<=1997], \n",
    "                                values='CumPaidLoss_D', \n",
    "                                index=['GRNAME','AccidentYear'], \n",
    "                                columns='DevelopmentLag')\n",
    "\n",
    "    John's code\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # use reshape method to create a 3-D Matrix of triangles\n",
    "    # triangle array is a set 10x10 triangles for more than 100 companies.\n",
    "    triangle_array = np.array(triangle_frame).reshape(\n",
    "        len(cas['GRNAME'].unique()),\n",
    "        len(cas['AccidentYear'].unique()),\n",
    "        len(cas['DevelopmentLag'].unique())\n",
    "    )\n",
    "    \n",
    "    # get rid of completely empty triangles\n",
    "    triangle_sum = np.nansum(np.nansum(triangle_array, axis=1),axis=1)\n",
    "    triangle_array = triangle_array[triangle_sum!=0,:,:]\n",
    "    triangle_array[triangle_array==0]=np.nan\n",
    "\n",
    "    # use slicing to create age-to-age factors\n",
    "    ata_array = triangle_array[:,:-1,1:]/triangle_array[:,:-1,:-1]\n",
    "    \n",
    "    # create an array of LDFs, by taking simple averages of the age-to-age factors; default missing to 1\n",
    "    ldf_array = np.nanmean(ata_array, axis=1)\n",
    "    ldf_array[np.isnan(ldf_array)] = 1.0\n",
    "\n",
    "    # create an array of CDFs with a tail factor from our LDFs\n",
    "    cdf_array = ldf_array[:,::-1].cumprod(axis=1)[:,::-1]\n",
    "    tail_factor = 1.0\n",
    "    cdf_array = np.append(cdf_array,np.expand_dims(np.repeat(tail_factor,cdf_array.shape[0]),1),axis=1)[:,::-1]\n",
    "\n",
    "    # strip latest diagonal and develop \n",
    "    latest_diagonal = np.nan_to_num(np.diagonal(triangle_array[:,::-1,],axis1=1,axis2=2)[:, ::-1])\n",
    "    ultimate = latest_diagonal * cdf_array\n",
    "    ibnr = ultimate - latest_diagonal\n",
    "    \n",
    "    # return the interesting bits \n",
    "    return triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# %%prun -s \"time\" -l 20\n",
    "triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr = develop_np(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr = develop_np(triangle_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_pd(triangle_frame):\n",
    "    '''\n",
    "    Same thing in pandas\n",
    "    '''\n",
    "\n",
    "    triangle_frame1 = triangle_frame.groupby(level=0).filter(lambda x : np.nansum(x)  > 0)\n",
    "\n",
    "    # ata factors, picks up index from second data frame \n",
    "    ata_df = triangle_frame1.iloc[:, 1:].values / triangle_frame1.iloc[:, :-1] \n",
    "\n",
    "    # ldfs with default 1 and tail factor in column 10\n",
    "    ldf_df = ata_df.groupby(level=0).mean().fillna(1.)\n",
    "    ldf_df[10] = 1.0\n",
    "\n",
    "    # cdfs \n",
    "    cdf_df = ldf_df.iloc[:, ::-1].cumprod(axis=1).iloc[:, ::-1]\n",
    "\n",
    "    # diagonal\n",
    "    diag_df = triangle_frame1.groupby(level=0).apply(lambda x : pd.Series(np.diagonal(x.values[:, ::-1])[::-1], index=x.columns))\n",
    "\n",
    "    # ultimate and ibnr\n",
    "    ult_df = (diag_df * cdf_df).fillna(0)\n",
    "    ibnr_df = ult_df - diag_df\n",
    "    ibnr_df['Tot'] = ibnr_df.sum(1)\n",
    "\n",
    "    # return interesting bits \n",
    "    return ldf_df, cdf_df, diag_df, ult_df, ibnr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# %%prun -s \"time\" -l 20\n",
    "ldf_df, cdf_df, diag_df, ult_df, ibnr_df = develop_pd(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df, cdf_df, diag_df, ult_df, ibnr_df = develop_pd(triangle_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we get the same answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ibnr_df.head(20).style)\n",
    "display(pd.DataFrame(ibnr[:,::-1]).head(20).style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ult_df.head(10))\n",
    "display(pd.DataFrame(ultimate).iloc[0:10, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(diag_df.head(10))\n",
    "display(pd.DataFrame(latest_diagonal).iloc[:10, 10::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cdf_df.head(10))\n",
    "display(pd.DataFrame(cdf_array).iloc[0:10, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ldf_df.head(10))\n",
    "display(pd.DataFrame(ldf_array).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Fun with More Triangles... \n",
    "\n",
    "Load and develop all triangles in the CAS database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = pd.read_csv(r'http://www.mynl.com/RPM/masterdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.describe().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.Line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = N1.query(' Lag == 10 ')[['GRName', 'Line', 'UltIncLoss', 'EarnedPrem']]  # .head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby('GRName').agg({ 'EarnedPrem': sum } ).sort_values('EarnedPrem', ascending=False).head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = N1.set_index(keys=['GRName', 'Line', 'AY', 'Lag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_cos = list( N1.query(' Lag == 10 ').groupby('GRName')[['EarnedPrem']].sum().nlargest(20, 'EarnedPrem').index ) \n",
    "big_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = N1.query(' AY + Lag <= 1998 ')[['GRName', 'Line', 'PaidLoss', 'CaseIncLoss', 'UltIncLoss', 'EarnedPrem', 'AY', 'Lag']] \n",
    "# just the big cos using isin\n",
    "bit = bit.loc[bit.GRName.isin(big_cos), :]\n",
    "bit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a particular randomly selected company \n",
    "sfm = 'State Farm Mut Grp' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pd.pivot_table(N1.query(' AY + Lag <= 1998 and GRName == @sfm '), values=['CaseIncLoss', 'PaidLoss'], index=['GRName', 'Line', 'AY'], columns='Lag')\n",
    "G.iloc[20:30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_ratios_from_raw_data(N1, opt_filter=''):\n",
    "    '''\n",
    "    Add link ratios to loss triangles\n",
    "    e.g. opt_filter = \" and GRName=='State Farm Mut Grp' \"\n",
    "    '''\n",
    "    G = pd.pivot_table(\n",
    "            N1.query(\" AY+Lag <= 1998 \" + opt_filter ), \n",
    "            values=['PaidLoss', 'CaseIncLoss'], \n",
    "            index=['GRName', 'Line', 'AY'], \n",
    "            columns='Lag'\n",
    "        )\n",
    "\n",
    "    return pd.concat((G, \n",
    "                      pd.DataFrame(G.iloc[:, 1:10].values / G.iloc[:, 0:9].values, \n",
    "                                   index=G.index, \n",
    "                                   columns=pd.MultiIndex.from_tuples([('CaseIncLink', i) for i in range(1,10)])),\n",
    "                      pd.DataFrame(G.iloc[:, 11:].values / G.iloc[:, 10:-1].values, \n",
    "                                   index=G.index, \n",
    "                                   columns=pd.MultiIndex.from_tuples([('PaidLink', i) for i in range(1,10)]))\n",
    "                     ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = add_link_ratios_from_raw_data(N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8 ms ± 3.85 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit G2 = add_link_ratios_from_raw_data(N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.xs(sfm, level=0).filter(regex='Paid').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.loc[sfm, 'PaidLink'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the complete triangles \n",
    "comp = G2.loc[G2.groupby(['GRName', 'Line']).apply(lambda x : x.isna().sum().sum()) == 180, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.shape, comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(n, size, kind):\n",
    "    \"\"\" \n",
    "    mask for avg last n in a size x size triangle \n",
    "    \"\"\"\n",
    "    nyrs = size - 1\n",
    "    if kind=='loss_den':\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(size)] for j in range(size)])\n",
    "    elif kind=='loss_num':\n",
    "        ans = np.array([[1 if i > 0 and i + j < size and i + j >= size - n else 0 for i in range(size)] for j in range(size)])\n",
    "    else:\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(nyrs)] for j in range(size)])\n",
    "    return ans\n",
    "\n",
    "def make_links(x, avg_tuple=(3, 5, 10)):\n",
    "    '''\n",
    "    Compute paid and incurred average link ratios, weight and straight, 3, 5 and all year averages (2x2x3=12 sets)\n",
    "    '''\n",
    "    return pd.DataFrame({ \\\n",
    "        **{ ('Inc', f'str {i}') : np.nansum(x.loc[:, 'CaseIncLink'].values * mask(i, 10, 'link'), 0) / np.nansum( mask(i, 10, 'link'), 0) for i in avg_tuple}, \\\n",
    "        **{ ('Pd', f'str {i}') :  np.nansum(x.loc[:, 'PaidLink'].values * mask(i, 10, 'link'), 0) /  np.nansum( mask(i, 10, 'link'), 0) for i in avg_tuple}, \\\n",
    "        **{ ('Inc', f'wtd {i}') : np.nansum((x.loc[:, 'CaseIncLoss'].values * mask(i, 10, 'loss_num')), 0)[1:] / \\\n",
    "                                  np.nansum((x.loc[:, 'CaseIncLoss'].values * mask(i, 10, 'loss_den')), 0)[:-1] for i in avg_tuple}, \\\n",
    "        **{ ('Pd', f'wtd {i}') :  np.nansum((x.loc[:, 'PaidLoss'].values * mask(i, 10, 'loss_num')), 0)[1:] / \\\n",
    "                                  np.nansum((x.loc[:, 'PaidLoss'].values * mask(i, 10, 'loss_den')), 0)[:-1] for i in avg_tuple}, \\\n",
    "        }, \\\n",
    "        index=pd.Index(range(1,10), name='Lag')).T\n",
    "\n",
    "# def make_links2(x, avg_tuple=(3, 5, 10)):\n",
    "#     '''\n",
    "#     Compute paid and incurred average link ratios, weight and straight, 3, 5 and all year averages (2x2x3=12 sets)\n",
    "#     Use masked arrays and dictionary list comprehensions \n",
    "#     SLOWER but probably correct for incomplete triangles.... \n",
    "#     '''\n",
    "#     return pd.DataFrame({ \\\n",
    "#         **{ (j, f'str {i}') : ma.masked_array(x.loc[:, j], mask(i, 10, 'link')).mean(0) \\\n",
    "#            for i in avg_tuple for j in ['CaseIncLink', 'PaidLink']}, \\\n",
    "#         **{ (j, f'wtd {i}') : ma.masked_array(x.loc[:, k], mask(i, 10, 'loss_num')).sum(0)[1:] / \\\n",
    "#            ma.masked_array(x.loc[:, k], mask2(i, 10, 'loss_den')).sum(0)[:-1] \\\n",
    "#            for i in avg_tuple for j, k in [('Inc', 'CaseIncLoss'), ('Pd', 'PaidLoss')]}, \\\n",
    "#         }, \\\n",
    "#         index=pd.Index(range(1,10), name='Lag')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = comp.groupby(level=['GRName', 'Line']).apply(make_links)\n",
    "links.index.names = ['GRName', 'Line', 'Kind', 'Method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskex(n, size, kind, tiles):\n",
    "    \"\"\" \n",
    "    mask for avg last n in a size x size triangle \n",
    "    \"\"\"\n",
    "    nyrs = size - 1\n",
    "    if kind=='loss_den':\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(size)] for j in range(size)])\n",
    "    elif kind=='loss_num':\n",
    "        ans = np.array([[1 if i > 0 and i + j < size and i + j >= size - n else 0 for i in range(size)] for j in range(size)])\n",
    "    else:\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(nyrs)] for j in range(size)])\n",
    "    return np.tile(ans, (tiles, 2))\n",
    "\n",
    "def mask_count(n, size):\n",
    "    n = min(n, size-1)\n",
    "    return np.tile(np.array([n]*(size-n-1) + list(range(n,0,-1))), 2)\n",
    "complete=comp\n",
    "bril = pd.concat([(complete.filter(regex='Loss', axis=1) * maskex(i, 10, 'loss_num', 400)).iloc[:, pd.np.r_[1:10, 11:20]].groupby(level=[0,1]).sum().values / \\\n",
    "           (complete.filter(regex='Loss', axis=1) * maskex(i, 10, 'loss_den', 400)).iloc[:, pd.np.r_[0:9, 10:19]].groupby(level=[0,1]).sum() for i in [3, 5, 10]]+\n",
    "           [(complete.filter(regex='Link', axis=1) * maskex(i, 10, 'link', 400)).groupby(level=[0,1]).sum() / mask_count(i, 10) for i in [3, 5, 10]],\n",
    "                    axis=1,\n",
    "                 keys=[(wt, i) for wt in ['Wtd', 'Str'] for i in [3, 5, 10]] ) \n",
    "bril.columns.names= ['Method', 'Nyrs', 'LossType', 'DY']\n",
    "bril = bril.stack(level=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>DY</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line</th>\n",
       "      <th>Method</th>\n",
       "      <th>Nyrs</th>\n",
       "      <th>LossType</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Comm Auto</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Str</th>\n",
       "      <th>3</th>\n",
       "      <th>CaseIncLink</th>\n",
       "      <td>1.293552</td>\n",
       "      <td>1.113861</td>\n",
       "      <td>1.060338</td>\n",
       "      <td>1.026891</td>\n",
       "      <td>1.018002</td>\n",
       "      <td>1.010766</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>CaseIncLink</th>\n",
       "      <td>1.313512</td>\n",
       "      <td>1.121383</td>\n",
       "      <td>1.064900</td>\n",
       "      <td>1.026766</td>\n",
       "      <td>1.016194</td>\n",
       "      <td>1.009682</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>CaseIncLink</th>\n",
       "      <td>1.339910</td>\n",
       "      <td>1.122061</td>\n",
       "      <td>1.065689</td>\n",
       "      <td>1.027940</td>\n",
       "      <td>1.016194</td>\n",
       "      <td>1.009682</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>PaidLink</th>\n",
       "      <td>1.826069</td>\n",
       "      <td>1.263130</td>\n",
       "      <td>1.128121</td>\n",
       "      <td>1.062332</td>\n",
       "      <td>1.039262</td>\n",
       "      <td>1.016685</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>PaidLink</th>\n",
       "      <td>1.890888</td>\n",
       "      <td>1.276082</td>\n",
       "      <td>1.136528</td>\n",
       "      <td>1.062149</td>\n",
       "      <td>1.037350</td>\n",
       "      <td>1.016063</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>PaidLink</th>\n",
       "      <td>1.929178</td>\n",
       "      <td>1.286610</td>\n",
       "      <td>1.140512</td>\n",
       "      <td>1.066676</td>\n",
       "      <td>1.037350</td>\n",
       "      <td>1.016063</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Wtd</th>\n",
       "      <th>3</th>\n",
       "      <th>CaseIncLoss</th>\n",
       "      <td>1.293524</td>\n",
       "      <td>1.113678</td>\n",
       "      <td>1.060463</td>\n",
       "      <td>1.026928</td>\n",
       "      <td>1.017973</td>\n",
       "      <td>1.010706</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>CaseIncLoss</th>\n",
       "      <td>1.312186</td>\n",
       "      <td>1.120616</td>\n",
       "      <td>1.064592</td>\n",
       "      <td>1.026813</td>\n",
       "      <td>1.016305</td>\n",
       "      <td>1.009717</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>CaseIncLoss</th>\n",
       "      <td>1.336434</td>\n",
       "      <td>1.121964</td>\n",
       "      <td>1.065358</td>\n",
       "      <td>1.027861</td>\n",
       "      <td>1.016305</td>\n",
       "      <td>1.009717</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>PaidLoss</th>\n",
       "      <td>1.826329</td>\n",
       "      <td>1.262811</td>\n",
       "      <td>1.127585</td>\n",
       "      <td>1.061927</td>\n",
       "      <td>1.039367</td>\n",
       "      <td>1.016560</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>PaidLoss</th>\n",
       "      <td>1.884683</td>\n",
       "      <td>1.274334</td>\n",
       "      <td>1.135774</td>\n",
       "      <td>1.061906</td>\n",
       "      <td>1.037541</td>\n",
       "      <td>1.016012</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>PaidLoss</th>\n",
       "      <td>1.920529</td>\n",
       "      <td>1.284353</td>\n",
       "      <td>1.139525</td>\n",
       "      <td>1.065953</td>\n",
       "      <td>1.037541</td>\n",
       "      <td>1.016012</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "DY                                        1         2         3         4  \\\n",
       "Line      Method Nyrs LossType                                              \n",
       "Comm Auto Str    3    CaseIncLink  1.293552  1.113861  1.060338  1.026891   \n",
       "                 5    CaseIncLink  1.313512  1.121383  1.064900  1.026766   \n",
       "                 10   CaseIncLink  1.339910  1.122061  1.065689  1.027940   \n",
       "                 3    PaidLink     1.826069  1.263130  1.128121  1.062332   \n",
       "                 5    PaidLink     1.890888  1.276082  1.136528  1.062149   \n",
       "                 10   PaidLink     1.929178  1.286610  1.140512  1.066676   \n",
       "          Wtd    3    CaseIncLoss  1.293524  1.113678  1.060463  1.026928   \n",
       "                 5    CaseIncLoss  1.312186  1.120616  1.064592  1.026813   \n",
       "                 10   CaseIncLoss  1.336434  1.121964  1.065358  1.027861   \n",
       "                 3    PaidLoss     1.826329  1.262811  1.127585  1.061927   \n",
       "                 5    PaidLoss     1.884683  1.274334  1.135774  1.061906   \n",
       "                 10   PaidLoss     1.920529  1.284353  1.139525  1.065953   \n",
       "\n",
       "DY                                        5         6         7         8  \\\n",
       "Line      Method Nyrs LossType                                              \n",
       "Comm Auto Str    3    CaseIncLink  1.018002  1.010766  1.005025  1.004704   \n",
       "                 5    CaseIncLink  1.016194  1.009682  1.005025  1.004704   \n",
       "                 10   CaseIncLink  1.016194  1.009682  1.005025  1.004704   \n",
       "                 3    PaidLink     1.039262  1.016685  1.008713  1.007015   \n",
       "                 5    PaidLink     1.037350  1.016063  1.008713  1.007015   \n",
       "                 10   PaidLink     1.037350  1.016063  1.008713  1.007015   \n",
       "          Wtd    3    CaseIncLoss  1.017973  1.010706  1.004824  1.004742   \n",
       "                 5    CaseIncLoss  1.016305  1.009717  1.004824  1.004742   \n",
       "                 10   CaseIncLoss  1.016305  1.009717  1.004824  1.004742   \n",
       "                 3    PaidLoss     1.039367  1.016560  1.008650  1.007079   \n",
       "                 5    PaidLoss     1.037541  1.016012  1.008650  1.007079   \n",
       "                 10   PaidLoss     1.037541  1.016012  1.008650  1.007079   \n",
       "\n",
       "DY                                        9  \n",
       "Line      Method Nyrs LossType               \n",
       "Comm Auto Str    3    CaseIncLink  1.011117  \n",
       "                 5    CaseIncLink  1.011117  \n",
       "                 10   CaseIncLink  1.011117  \n",
       "                 3    PaidLink     1.015636  \n",
       "                 5    PaidLink     1.015636  \n",
       "                 10   PaidLink     1.015636  \n",
       "          Wtd    3    CaseIncLoss  1.011117  \n",
       "                 5    CaseIncLoss  1.011117  \n",
       "                 10   CaseIncLoss  1.011117  \n",
       "                 3    PaidLoss     1.015636  \n",
       "                 5    PaidLoss     1.015636  \n",
       "                 10   PaidLoss     1.015636  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bril.loc[sfm].head(12).sort_index(level=[0,1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Lag</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Comm Auto</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Inc</th>\n",
       "      <th>str 3</th>\n",
       "      <td>1.293552</td>\n",
       "      <td>1.113861</td>\n",
       "      <td>1.060338</td>\n",
       "      <td>1.026891</td>\n",
       "      <td>1.018002</td>\n",
       "      <td>1.010766</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str 5</th>\n",
       "      <td>1.313512</td>\n",
       "      <td>1.121383</td>\n",
       "      <td>1.064900</td>\n",
       "      <td>1.026766</td>\n",
       "      <td>1.016194</td>\n",
       "      <td>1.009682</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str 10</th>\n",
       "      <td>1.339910</td>\n",
       "      <td>1.122061</td>\n",
       "      <td>1.065689</td>\n",
       "      <td>1.027940</td>\n",
       "      <td>1.016194</td>\n",
       "      <td>1.009682</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>1.004704</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Pd</th>\n",
       "      <th>str 3</th>\n",
       "      <td>1.826069</td>\n",
       "      <td>1.263130</td>\n",
       "      <td>1.128121</td>\n",
       "      <td>1.062332</td>\n",
       "      <td>1.039262</td>\n",
       "      <td>1.016685</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str 5</th>\n",
       "      <td>1.890888</td>\n",
       "      <td>1.276082</td>\n",
       "      <td>1.136528</td>\n",
       "      <td>1.062149</td>\n",
       "      <td>1.037350</td>\n",
       "      <td>1.016063</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str 10</th>\n",
       "      <td>1.929178</td>\n",
       "      <td>1.286610</td>\n",
       "      <td>1.140512</td>\n",
       "      <td>1.066676</td>\n",
       "      <td>1.037350</td>\n",
       "      <td>1.016063</td>\n",
       "      <td>1.008713</td>\n",
       "      <td>1.007015</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Inc</th>\n",
       "      <th>wtd 3</th>\n",
       "      <td>1.293524</td>\n",
       "      <td>1.113678</td>\n",
       "      <td>1.060463</td>\n",
       "      <td>1.026928</td>\n",
       "      <td>1.017973</td>\n",
       "      <td>1.010706</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd 5</th>\n",
       "      <td>1.312186</td>\n",
       "      <td>1.120616</td>\n",
       "      <td>1.064592</td>\n",
       "      <td>1.026813</td>\n",
       "      <td>1.016305</td>\n",
       "      <td>1.009717</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd 10</th>\n",
       "      <td>1.336434</td>\n",
       "      <td>1.121964</td>\n",
       "      <td>1.065358</td>\n",
       "      <td>1.027861</td>\n",
       "      <td>1.016305</td>\n",
       "      <td>1.009717</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>1.004742</td>\n",
       "      <td>1.011117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Pd</th>\n",
       "      <th>wtd 3</th>\n",
       "      <td>1.826329</td>\n",
       "      <td>1.262811</td>\n",
       "      <td>1.127585</td>\n",
       "      <td>1.061927</td>\n",
       "      <td>1.039367</td>\n",
       "      <td>1.016560</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd 5</th>\n",
       "      <td>1.884683</td>\n",
       "      <td>1.274334</td>\n",
       "      <td>1.135774</td>\n",
       "      <td>1.061906</td>\n",
       "      <td>1.037541</td>\n",
       "      <td>1.016012</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtd 10</th>\n",
       "      <td>1.920529</td>\n",
       "      <td>1.284353</td>\n",
       "      <td>1.139525</td>\n",
       "      <td>1.065953</td>\n",
       "      <td>1.037541</td>\n",
       "      <td>1.016012</td>\n",
       "      <td>1.008650</td>\n",
       "      <td>1.007079</td>\n",
       "      <td>1.015636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Lag                           1         2         3         4         5  \\\n",
       "Line      Kind Method                                                     \n",
       "Comm Auto Inc  str 3   1.293552  1.113861  1.060338  1.026891  1.018002   \n",
       "               str 5   1.313512  1.121383  1.064900  1.026766  1.016194   \n",
       "               str 10  1.339910  1.122061  1.065689  1.027940  1.016194   \n",
       "          Pd   str 3   1.826069  1.263130  1.128121  1.062332  1.039262   \n",
       "               str 5   1.890888  1.276082  1.136528  1.062149  1.037350   \n",
       "               str 10  1.929178  1.286610  1.140512  1.066676  1.037350   \n",
       "          Inc  wtd 3   1.293524  1.113678  1.060463  1.026928  1.017973   \n",
       "               wtd 5   1.312186  1.120616  1.064592  1.026813  1.016305   \n",
       "               wtd 10  1.336434  1.121964  1.065358  1.027861  1.016305   \n",
       "          Pd   wtd 3   1.826329  1.262811  1.127585  1.061927  1.039367   \n",
       "               wtd 5   1.884683  1.274334  1.135774  1.061906  1.037541   \n",
       "               wtd 10  1.920529  1.284353  1.139525  1.065953  1.037541   \n",
       "\n",
       "Lag                           6         7         8         9  \n",
       "Line      Kind Method                                          \n",
       "Comm Auto Inc  str 3   1.010766  1.005025  1.004704  1.011117  \n",
       "               str 5   1.009682  1.005025  1.004704  1.011117  \n",
       "               str 10  1.009682  1.005025  1.004704  1.011117  \n",
       "          Pd   str 3   1.016685  1.008713  1.007015  1.015636  \n",
       "               str 5   1.016063  1.008713  1.007015  1.015636  \n",
       "               str 10  1.016063  1.008713  1.007015  1.015636  \n",
       "          Inc  wtd 3   1.010706  1.004824  1.004742  1.011117  \n",
       "               wtd 5   1.009717  1.004824  1.004742  1.011117  \n",
       "               wtd 10  1.009717  1.004824  1.004742  1.011117  \n",
       "          Pd   wtd 3   1.016560  1.008650  1.007079  1.015636  \n",
       "               wtd 5   1.016012  1.008650  1.007079  1.015636  \n",
       "               wtd 10  1.016012  1.008650  1.007079  1.015636  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.loc[sfm].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 ms ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bril = pd.concat([(complete.filter(regex='Loss', axis=1) * maskex(i, 10, 'loss_num', 400)).iloc[:, pd.np.r_[1:10, 11:20]].groupby(level=[0,1]).sum().values / \\\n",
    "           (complete.filter(regex='Loss', axis=1) * maskex(i, 10, 'loss_den', 400)).iloc[:, pd.np.r_[0:9, 10:19]].groupby(level=[0,1]).sum() for i in [3, 5, 10]]+\n",
    "           [(complete.filter(regex='Link', axis=1) * maskex(i, 10, 'link', 400)).groupby(level=[0,1]).sum() / mask_count(i, 10) for i in [3, 5, 10]],\n",
    "                    axis=1,\n",
    "                 keys=[(wt, i) for wt in ['Wtd', 'Str'] for i in [3, 5, 10]] ) \n",
    "bril.columns.names= ['Method', 'Nyrs', 'LossType', 'DY']\n",
    "bril = bril.stack(level=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 s ± 175 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "links0 = complete.groupby(level=['GRName', 'Line']).apply(make_links)\n",
    "links0.index.names = ['GRName', 'Line', 'Kind', 'Method']\n",
    "links0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfm ppa results\n",
    "links.loc[[sfm]].iloc[24:36, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bootstrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_inc_plot(df, co_name='', line_name='', bins=201, dd=True, ax=None, legend=False):\n",
    "    '''\n",
    "    bootstrap from paid and incurred and create product distribution \n",
    "    input is result of running\n",
    "    \n",
    "        links = comp.groupby(level=['GRName', 'Line']).apply(make_links)\n",
    "        links.index.names = ['GRName', 'Line', 'Kind', 'Method']\n",
    "    \n",
    "    i.e. df has index GRName, Line, AY and col groups for Paid, CaseInc loss and links  and lag \n",
    "    '''\n",
    "\n",
    "    def shorten(s):\n",
    "        '''\n",
    "        name shortening function for labels \n",
    "        '''\n",
    "        if len(s) < 12:\n",
    "            return s\n",
    "        else:\n",
    "            re.sub\n",
    "            s = re.sub(' (Co|Ins|Grp|Exchange|Of|Inc|of)', '', s)\n",
    "            s = s.replace('Agricultural', 'Ag').replace('Exchange', 'Ex'). replace('Associated', 'Assoc')\n",
    "        if len(s) > 12:\n",
    "            s = ' '.join([i[:4] for i in s.split(' ')][:3])\n",
    "        return s\n",
    "    # allows use with groupby\n",
    "    if co_name == '':\n",
    "        co_name, line_name, _ = df.index[0]\n",
    "   \n",
    "    yrs = list(df.index.get_level_values('AY').unique())\n",
    "    nyrs = yrs[-1] - yrs[0]\n",
    "    \n",
    "    # piece of interest\n",
    "    bit = df.xs((co_name, line_name), level=('GRName', 'Line'))\n",
    "    \n",
    "    if len(bit) < 10:\n",
    "        return\n",
    "    \n",
    "    # make kronecker products \n",
    "    # pull off most recent year losses \n",
    "    kpi = np.array(bit.loc[yrs[-1], ('CaseIncLoss', 1)])\n",
    "    kpp = np.array(bit.loc[yrs[-1], ('PaidLoss', 1)])\n",
    "    \n",
    "    # and complete with link ratios \n",
    "    for i in range(0, nyrs):\n",
    "        kpp = np.kron(kpp, bit.loc[yrs[0]:yrs[0]+i, ('PaidLink', nyrs - i)])\n",
    "        kpi = np.kron(kpi, bit.loc[yrs[0]:yrs[0]+i, ('CaseIncLink', nyrs - i)])\n",
    "\n",
    "    ult = pd.DataFrame( {'inc' : kpi, 'pd' : kpp})\n",
    "    # stats \n",
    "    d = ult.describe().iloc[1:, :]\n",
    "    if dd:\n",
    "        display(d)\n",
    "    \n",
    "    if ax is None:\n",
    "        f = plt.figure()\n",
    "        a = f.gca()\n",
    "    else:\n",
    "        a = next(ax)\n",
    "    \n",
    "    bp = np.linspace(d.loc['min', :].min(), d.loc['max', :].max(), bins)\n",
    "    mnn = d.loc['mean', :].min()\n",
    "    mnx = d.loc['mean', :].max()\n",
    "    sd = d.loc['std', : ].max()\n",
    "    bp = np.linspace(max(0, mnn - 4*sd), mnx + 4*sd, bins)\n",
    "    npd,  _, _ = a.hist(kpp, bins=bp, color='b', alpha=0.5, label='Paid')\n",
    "    ninc, _, _ = a.hist(kpi, bins=bp, color='r', alpha=0.5, label='Incurred')\n",
    "    bay = ninc*npd / sum(ninc*npd) * sum(npd)\n",
    "    xs = (bp[1:]+bp[0:-1])/2\n",
    "    a.plot(xs, bay, '-g', label='Posterior')\n",
    "    if legend:\n",
    "        a.legend(frameon=False)\n",
    "    a.set(title='{:}/{:}\\nMLE={:,.1f}, CV(I/Pd)={:.3f}/{:.3f}'.format(shorten(co_name), line_name, xs[bay.argmax()]/1e3, \n",
    "                                                                *(d.loc['std']/d.loc['mean']) ))\n",
    "    return ult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(N1.Line.unique())\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(12,8))\n",
    "ax = iter(ax.flatten())\n",
    "for l in lines:\n",
    "    ult = pd_inc_plot(comp, sfm, l, dd=False, ax=ax, legend=(l==lines[0]))\n",
    "# tidy up \n",
    "for a in ax:\n",
    "    f.delaxes(a)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(df, line='', co='', threshold=250000):\n",
    "    '''\n",
    "    all lines for given co or all cos for given line \n",
    "    '''\n",
    "    if line=='' and co=='':\n",
    "        return \n",
    "    \n",
    "    if line != '':\n",
    "        bit = df.query(f' Line==\"{line}\" ')        \n",
    "        ncos = len(bit) / 10 \n",
    "        nr = int(ncos/6)\n",
    "        if nr < ncos/6: nr += 1\n",
    "        f, ax = plt.subplots(nr, 6, figsize=(18, 2.4*nr))\n",
    "        ax = iter(ax.flatten())\n",
    "        \n",
    "    elif co != '':\n",
    "        bit = df.query(f' GRName==\"{co}\" ')\n",
    "        f, ax = plt.subplots(2, 3, figsize=(12,6))\n",
    "        ax = iter(ax.flatten())\n",
    "    \n",
    "    g = bit.groupby(['GRName', 'Line'])\n",
    "\n",
    "    l = True\n",
    "    for k, v in g.groups.items():\n",
    "        grp = bit.loc[v]\n",
    "        if grp.CaseIncLoss.sum().sum() > threshold:\n",
    "            ult = pd_inc_plot(grp, dd=False, ax=ax, legend=l)\n",
    "            l = False\n",
    "        \n",
    "    # tidy up \n",
    "    for a in ax:\n",
    "        f.delaxes(a)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in comp.index.get_level_values('GRName').unique() if i[:5] == 'Canal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(comp, 'PP Auto', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(comp, 'Work Comp', 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For SciKit-Learn Intro --> For this afternoon's session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CAS data\n",
    "data_url = 'https://www.casact.org/research/reserve_data'\n",
    "lobs = ['medmal','ppauto','wkcomp', 'othliab', 'comauto', 'prodliab']\n",
    "data = pd.DataFrame()\n",
    "data = []\n",
    "columns = ['GRCODE','GRNAME','AccidentYear','DevelopmentYear','DevelopmentLag'\n",
    "           ,'IncurLoss', 'CumPaidLoss','BulkLoss','EarnedPremDIR'\n",
    "           ,'EarnedPremCeded','EarnedPremNet', 'Single','PostedReserve97']\n",
    "for lob in lobs:\n",
    "    file_url = f'{data_url}/{lob}_pos.csv'\n",
    "    subset = pd.read_csv(file_url, names=columns, skiprows=1)\n",
    "    subset['LOB'] = lob\n",
    "    data.append(subset)\n",
    "data1 = pd.concat(data)\n",
    "data = data1.query(\" DevelopmentYear <= 1997 \").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triangles(data, nlarge=20):\n",
    "    '''\n",
    "    make ldf triangles from CAS data for largest companies\n",
    "    '''\n",
    "    aggregates2 = data.query(' DevelopmentYear ==  1997 ').groupby(['LOB','GRNAME'])['IncurLoss'].sum() \n",
    "    top_by_lob = aggregates2.groupby(level='LOB').apply(lambda x : x.nlargest(nlarge).reset_index(level=0, drop=True))\n",
    "    \n",
    "    data_alt2 = data.merge(top_by_lob.to_frame(), how='left', left_on=['LOB','GRNAME'], right_index=True)\n",
    "    data_alt2.loc[data_alt2.loc[:,'IncurLoss_y'].isna(), 'GRNAME'] = 'Other'\n",
    "    \n",
    "    # create triangles \n",
    "    triangles = pd.pivot_table(data_alt2, index=['GRNAME','LOB','AccidentYear'],\n",
    "                           columns='DevelopmentLag', values='CumPaidLoss')\n",
    "    \n",
    "    # Determine LDF Weights ORIG\n",
    "    w = pd.DataFrame(np.array([[1 if i+j<9 else 0 for i in range(9)] for j in range(10)]))\n",
    "    weight = np.tile(w, (int(triangles.shape[0]/10), 1))\n",
    "    columns = [f'{triangles.columns[num]}-{triangles.columns[num+1]}'\n",
    "               for num, item in enumerate(triangles.columns[:-1])]\n",
    "\n",
    "    # Volume-weighted numerator and demoninator mask for denom only; values on num because want index from num \n",
    "    ldf = (triangles.iloc[:,1:].groupby(level=['GRNAME','LOB']).sum().values / \\\n",
    "           (weight*triangles.iloc[:,:-1]).groupby(level=['GRNAME','LOB']).sum()).fillna(1.0) \n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldfs = make_triangles(data, 20)\n",
    "plot_data = pd.DataFrame(ldfs.stack(), columns=['avg_link']).reset_index()\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=plot_data, kind='line', x='DevelopmentLag', y='avg_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data['trans'] = np.log(plot_data.avg_link - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.relplot(data=plot_data.query('DevelopmentLag >= 1'), kind='line', x='DevelopmentLag', y='trans', hue='GRNAME', col='LOB', col_wrap=3, legend=False)\n",
    "# for ax in a.axes.flatten():\n",
    "#     ax.set(ylim=[0.9,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
