{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import textwrap \n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "\n",
    "np.set_printoptions(linewidth =  160)\n",
    "\n",
    "def wdid(ob, ex=False):\n",
    "    ''' what does object do? \n",
    "    '''\n",
    "    print('\\n'.join(textwrap.wrap(' '.join([i for i in dir(ob) if i[0] != '_']), 80)))\n",
    "    if ex:\n",
    "    # optional pause for something more advanced... \n",
    "        for m in [ i for i in dir(np) if i[0] >= 'a' and i[0]<='z']:\n",
    "            print(f'\\n\\n{m}\\n{\"=\"*len(m)}\\n')\n",
    "            print(np.__getattribute__(m).__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manipulating Triangle Data in Pandas 1: WC Triangles  \n",
    "\n",
    "Building a multi-dimensional IBNR model in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Data and Basic Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cas = pd.read_csv(r'http://www.casact.org/research/reserve_data/wkcomp_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's make the pandas dataframe look more triangle like\n",
    "triangle_frame = pd.pivot_table(cas[cas['DevelopmentYear']<=1997], \n",
    "                                values='CumPaidLoss_D', \n",
    "                                index=['GRNAME','AccidentYear'], \n",
    "                                columns='DevelopmentLag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of zero triangles\n",
    "triangle_frame = triangle_frame.groupby(level=0).filter(lambda x : np.nansum(x)  > 0)\n",
    "triangle_frame.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[-10:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Age-to-age factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[0:20, 1:] / triangle_frame.iloc[0:20, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[0:20, 1:].values / triangle_frame.iloc[0:20, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_frame.iloc[0:20, 1:].values / triangle_frame.iloc[0:20, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ata_df = triangle_frame.iloc[:, 1:].values / triangle_frame.iloc[:, :-1]\n",
    "ata_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDFs and CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df = ata_df.groupby(level=0).mean().fillna(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdfs need cumulative product in reverse...easy to reverse and re-reverse\n",
    "cdf_df = ldf_df.iloc[:, ::-1].cumprod(axis=1).iloc[:, ::-1]\n",
    "cdf_df[10] = 1.\n",
    "cdf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ultimates and IBNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulling off the diagonal is a bit tricky \n",
    "diag_df = triangle_frame.groupby(level=0).apply(lambda x : pd.Series(np.diagonal(x.values[:, ::-1])[::-1], index=range(1,11)))\n",
    "diag_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ult_df = (diag_df * cdf_df).fillna(0)\n",
    "ibnr_df = ult_df - diag_df\n",
    "ult.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The business questions answered by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complte in pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "companies = np.array(triangle_frame.index.levels[0])[triangle_sum!=0]\n",
    "print('How much IBNR does the entire industry need according to this model?')\n",
    "print(np.sum(ibnr).round(0))\n",
    "print()\n",
    "print('What is the average ultimate to paid ratio across the industry?')\n",
    "print((np.sum(ultimate)/np.sum(latest_diagonal)).round(3))\n",
    "print()\n",
    "print('Which company has the highest 12-Ultimate CDF?')\n",
    "print(companies[np.argmax(cdf_array[:,0])])\n",
    "print()\n",
    "print('Which company has the lowest 12-24 LDF?')\n",
    "print(companies[np.argmin(ldf_array[:,1])])\n",
    "print()\n",
    "print('What is the 95% confidence interval on the estimate of 12-Ultimate CDF?')\n",
    "print((np.sort(cdf_array[:,1])[int(.025*len(cdf_array[:,1]))],cdf_array[:,1][int(.975*len(cdf_array[:,1]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance test of the above code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from cas\n",
    "triangle_frame = pd.pivot_table(cas[cas['DevelopmentYear']<=1997], \n",
    "                                values='CumPaidLoss_D', \n",
    "                                index=['GRNAME','AccidentYear'], \n",
    "                                columns='DevelopmentLag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def develop_np(triangle_frame):\n",
    "    '''\n",
    "    create latest ldfs, cdfs, diagonal, ultimate and ibnr ndarrays from\n",
    "    input pandas dataframe:\n",
    "    \n",
    "        pd.pivot_table(cas[cas['DevelopmentYear']<=1997], \n",
    "                                values='CumPaidLoss_D', \n",
    "                                index=['GRNAME','AccidentYear'], \n",
    "                                columns='DevelopmentLag')\n",
    "\n",
    "    John's code\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # use reshape method to create a 3-D Matrix of triangles\n",
    "    # triangle array is a set 10x10 triangles for more than 100 companies.\n",
    "    triangle_array = np.array(triangle_frame).reshape(\n",
    "        len(cas['GRNAME'].unique()),\n",
    "        len(cas['AccidentYear'].unique()),\n",
    "        len(cas['DevelopmentLag'].unique())\n",
    "    )\n",
    "    \n",
    "    # get rid of completely empty triangles\n",
    "    triangle_sum = np.nansum(np.nansum(triangle_array, axis=1),axis=1)\n",
    "    triangle_array = triangle_array[triangle_sum!=0,:,:]\n",
    "    triangle_array[triangle_array==0]=np.nan\n",
    "\n",
    "    # use slicing to create age-to-age factors\n",
    "    ata_array = triangle_array[:,:-1,1:]/triangle_array[:,:-1,:-1]\n",
    "    \n",
    "    # default the completely blank age-to-age columns to 1.0\n",
    "#     accident_periods = len(cas['DevelopmentLag'].unique())\n",
    "#     ata_array_defaults = np.expand_dims(np.all(np.isnan(ata_array),axis=1),axis=1)\n",
    "#     ata_array[np.repeat(ata_array_defaults,accident_periods-1,axis=1)]=1.0\n",
    "\n",
    "    # create an array of LDFs, by taking simple averages of the age-to-age factors; default missing to 1\n",
    "    ldf_array = np.nanmean(ata_array, axis=1)\n",
    "    ldf_array[np.isnan(ldf_array)] = 1.0\n",
    "\n",
    "    # create an array of CDFs with a tail factor from our LDFs\n",
    "    cdf_array = ldf_array[:,::-1].cumprod(axis=1)[:,::-1]\n",
    "    tail_factor = 1.0\n",
    "    cdf_array = np.append(cdf_array,np.expand_dims(np.repeat(tail_factor,cdf_array.shape[0]),1),axis=1)[:,::-1]\n",
    "\n",
    "    # strip latest diagonal and develop \n",
    "    latest_diagonal = np.nan_to_num(np.diagonal(triangle_array[:,::-1,],axis1=1,axis2=2)[:, ::-1])\n",
    "    ultimate = latest_diagonal * cdf_array\n",
    "    ibnr = ultimate - latest_diagonal\n",
    "    \n",
    "    # return the interesting bits \n",
    "    return triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -s \"time\" -l 20\n",
    "# %%timeit\n",
    "triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr = develop_np(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_array, triangle_sum, ldf_array, cdf_array, latest_diagonal, ultimate, ibnr = develop_np(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = np.array(triangle_frame.index.levels[0])[triangle_sum!=0]\n",
    "print('How much IBNR does the entire industry need according to this model?')\n",
    "print(np.sum(ibnr).round(0))\n",
    "print()\n",
    "print('What is the average ultimate to paid ratio across the industry?')\n",
    "print((np.sum(ultimate)/np.sum(latest_diagonal)).round(3))\n",
    "print()\n",
    "print('Which company has the highest 12-Ultimate CDF?')\n",
    "print(companies[np.argmax(cdf_array[:,0])])\n",
    "print()\n",
    "print('Which company has the lowest 12-24 LDF?')\n",
    "print(companies[np.argmin(ldf_array[:,1])])\n",
    "print()\n",
    "print('What is the 95% confidence interval on the estimate of 12-Ultimate CDF?')\n",
    "print(*np.sort(cdf_array[:,-1])[[int(.025*len(cdf_array)),\n",
    "       int(.975*len(cdf_array[:,1]))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_pd(triangle_frame):\n",
    "    '''\n",
    "    Same thing in pandas\n",
    "    '''\n",
    "\n",
    "    triangle_frame1 = triangle_frame.groupby(level=0).filter(lambda x : np.nansum(x)  > 0)\n",
    "\n",
    "    # ata factors, picks up index from second data frame \n",
    "    ata_df = triangle_frame1.iloc[:, 1:].values / triangle_frame1.iloc[:, :-1] \n",
    "\n",
    "    # ldfs with default 1 and tail factor in column 10\n",
    "    ldf_df = ata_df.groupby(level=0).mean().fillna(1.)\n",
    "    ldf_df[10] = 1.0\n",
    "\n",
    "    # cdfs \n",
    "    cdf_df = ldf_df.iloc[:, ::-1].cumprod(axis=1).iloc[:, ::-1]\n",
    "\n",
    "    # diagonal\n",
    "    diag_df = triangle_frame1.groupby(level=0).apply(lambda x : pd.Series(np.diagonal(x.values[:, ::-1])[::-1], index=x.columns))\n",
    "\n",
    "    # ultimate and ibnr\n",
    "    ult_df = (diag_df * cdf_df).fillna(0)\n",
    "    ibnr_df = ult_df - diag_df\n",
    "    ibnr_df['Tot'] = ibnr_df.sum(1)\n",
    "\n",
    "    # return interesting bits \n",
    "    return ldf_df, cdf_df, diag_df, ult_df, ibnr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -s \"time\" -l 20\n",
    "ldf_df, cdf_df, diag_df, ult_df, ibnr_df = develop_pd(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_df, cdf_df, diag_df, ult_df, ibnr_df = develop_pd(triangle_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr_df.sort_values('Tot', ascending=False).head(40).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we get the same answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ibnr_df.head(20).style)\n",
    "display(pd.DataFrame(ibnr[:,::-1]).head(20).style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ult_df.head(10))\n",
    "display(pd.DataFrame(ultimate).iloc[0:10, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(diag_df.head(10))\n",
    "display(pd.DataFrame(latest_diagonal).iloc[:10, 10::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cdf_df.head(10))\n",
    "display(pd.DataFrame(cdf_array).iloc[0:10, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ldf_df.head(10))\n",
    "display(pd.DataFrame(ldf_array).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SM Triangles\n",
    "\n",
    "Load and develop all triangles in the CAS database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = pd.read_csv(r'http://www.mynl.com/RPM/masterdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.describe().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = N1.query(' Lag == 10 ')[['GRName', 'Line', 'UltIncLoss', 'EarnedPrem']]  # .head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby('GRName').agg({ 'EarnedPrem': sum } ).sort_values('EarnedPrem', ascending=False).head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilist = ['GRName', 'Line'] \n",
    "ans = pd.concat([ bit.assign( **{x: 'total' for x in ilist[i:]} ).groupby(ilist).sum()\n",
    "          for i in range(len(ilist)+1)]).sort_index()\n",
    "ans['LR'] = ans.UltIncLoss / ans.EarnedPrem\n",
    "ans.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[['EarnedPrem']].unstack(level=1, fill_value=0). \\\n",
    "    sort_values(('EarnedPrem', 'total'), ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[['EarnedPrem', 'LR']].unstack(level=1, fill_value=0). \\\n",
    "    sort_values(('EarnedPrem', 'total'), ascending=False)[['LR']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = N1.query(' Lag == 1 ')[['GRName', 'Line', 'PaidLoss', 'CaseIncLoss', 'UltIncLoss', 'EarnedPrem']] \n",
    "bit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(np.log(bit.PaidLoss), np.log(bit.UltIncLoss), 'x', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(np.log(np.log(N1.PaidLoss)), np.log(np.log(N1.UltIncLoss)), 'x', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(N1.Line) # , pd.unique(N1.GRName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit N1[ (N1.GRName == 'Alaska Nat Ins Co') & (N1.Line=='Comm Auto')].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit N1.query(' GRName == \"Alaska Nat Ins Co\" and Line==\"Comm Auto\" ').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bit = N1.query(' AY + Lag <= 1999 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = N1.set_index(keys=['GRName', 'Line', 'AY', 'Lag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit N2.loc[(\"Alaska Nat Ins Co\", \"Comm Auto\"), :].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.loc[ 'FM Global', :].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.loc[(slice(None), 'Comm Auto'), :].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.loc[(slice(None), slice(None), 1990), :].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.xs(('Canal Ins Co Grp', 'Comm Auto'), level=('GRName', 'Line')).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2.xs('Comm Auto', level='Line').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_cos = list( N1.query(' Lag == 10 ').groupby('GRName')[['EarnedPrem']].sum().sort_values('EarnedPrem').tail(20).index ) \n",
    "big_cos = list( N1.query(' Lag == 10 ').groupby('GRName')[['EarnedPrem']].sum().nlargest(20, 'EarnedPrem').index ) \n",
    "big_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.loc[bit.GRName.isin(big_cos), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = N1.query(' AY + Lag <= 1998 ')[['GRName', 'Line', 'PaidLoss', 'CaseIncLoss', 'UltIncLoss', 'EarnedPrem', 'AY', 'Lag']] \n",
    "# just the big cos\n",
    "bit = bit.loc[bit.GRName.isin(big_cos), :]\n",
    "bit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = 'State Farm Mut Grp' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pd.pivot_table(bit, values=['CaseIncLoss', 'PaidLoss'], index=['GRName', 'Line', 'AY'], columns='Lag')\n",
    "G.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pd.pivot_table(N1.query(\" AY+Lag <= 1998 and GRName=='State Farm Mut Grp' \"), values=['PaidLoss', 'CaseIncLoss'], index=['GRName', 'Line', 'AY'], columns='Lag')\n",
    "G.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_ratios_from_raw_data(N1, opt_filter=''):\n",
    "    '''\n",
    "    Add link ratios to loss triangles\n",
    "    e.g. opt_filter = \" and GRName=='State Farm Mut Grp' \"\n",
    "    '''\n",
    "    G = pd.pivot_table(\n",
    "            N1.query(\" AY+Lag <= 1998 \" + opt_filter ), \n",
    "            values=['PaidLoss', 'CaseIncLoss'], \n",
    "            index=['GRName', 'Line', 'AY'], \n",
    "            columns='Lag'\n",
    "        )\n",
    "\n",
    "    return pd.concat((G, \n",
    "                      pd.DataFrame(G.iloc[:, 1:10].values / G.iloc[:, 0:9].values, \n",
    "                                   index=G.index, \n",
    "                                   columns=pd.MultiIndex.from_tuples([('CaseIncLink', i) for i in range(1,10)])),\n",
    "                      pd.DataFrame(G.iloc[:, 11:].values / G.iloc[:, 10:-1].values, \n",
    "                                   index=G.index, \n",
    "                                   columns=pd.MultiIndex.from_tuples([('PaidLink', i) for i in range(1,10)]))\n",
    "                     ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = add_link_ratios_from_raw_data(N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.xs(sfm, level=0).filter(regex='Paid').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.loc[sfm, 'PaidLink'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the complete triangles \n",
    "comp = G2.loc[G2.groupby(['GRName', 'Line']).apply(lambda x : x.isna().sum().sum()) == 180, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.shape, comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(n, size, kind):\n",
    "    \"\"\" \n",
    "    mask for avg last n in a size x size triangle \n",
    "    \"\"\"\n",
    "    nyrs = size - 1\n",
    "    if kind=='loss_den':\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(size)] for j in range(size)])\n",
    "    elif kind=='loss_num':\n",
    "        ans = np.array([[1 if i > 0 and i + j < size and i + j >= size - n else 0 for i in range(size)] for j in range(size)])\n",
    "    else:\n",
    "        ans = np.array([[1 if i + j < nyrs and i + j >= nyrs - n else 0 for i in range(nyrs)] for j in range(size)])\n",
    "    return ans\n",
    "\n",
    "def make_links(x, avg_tuple=(3, 5, 10)):\n",
    "    '''\n",
    "    Compute paid and incurred average link ratios, weight and straight, 3, 5 and all year averages (2x2x3=12 sets)\n",
    "    '''\n",
    "    return pd.DataFrame({ \\\n",
    "        **{ ('Inc', f'str {i}') : np.nansum(x.loc[:, 'CaseIncLink'].values * mask(i, 10, 'link'), 0) / np.nansum( mask(i, 10, 'link'), 0) for i in avg_tuple}, \\\n",
    "        **{ ('Pd', f'str {i}') :  np.nansum(x.loc[:, 'PaidLink'].values * mask(i, 10, 'link'), 0) /  np.nansum( mask(i, 10, 'link'), 0) for i in avg_tuple}, \\\n",
    "        **{ ('Inc', f'wtd {i}') : np.nansum((x.loc[:, 'CaseIncLoss'].values * mask(i, 10, 'loss_num')), 0)[1:] / \\\n",
    "                                  np.nansum((x.loc[:, 'CaseIncLoss'].values * mask(i, 10, 'loss_den')), 0)[:-1] for i in avg_tuple}, \\\n",
    "        **{ ('Pd', f'wtd {i}') :  np.nansum((x.loc[:, 'PaidLoss'].values * mask(i, 10, 'loss_num')), 0)[1:] / \\\n",
    "                                  np.nansum((x.loc[:, 'PaidLoss'].values * mask(i, 10, 'loss_den')), 0)[:-1] for i in avg_tuple}, \\\n",
    "        }, \\\n",
    "        index=pd.Index(range(1,10), name='Lag')).T\n",
    "\n",
    "# def make_links2(x, avg_tuple=(3, 5, 10)):\n",
    "#     '''\n",
    "#     Compute paid and incurred average link ratios, weight and straight, 3, 5 and all year averages (2x2x3=12 sets)\n",
    "#     Use masked arrays and dictionary list comprehensions \n",
    "#     SLOWER but probably correct for incomplete triangles.... \n",
    "#     '''\n",
    "#     return pd.DataFrame({ \\\n",
    "#         **{ (j, f'str {i}') : ma.masked_array(x.loc[:, j], mask(i, 10, 'link')).mean(0) \\\n",
    "#            for i in avg_tuple for j in ['CaseIncLink', 'PaidLink']}, \\\n",
    "#         **{ (j, f'wtd {i}') : ma.masked_array(x.loc[:, k], mask(i, 10, 'loss_num')).sum(0)[1:] / \\\n",
    "#            ma.masked_array(x.loc[:, k], mask2(i, 10, 'loss_den')).sum(0)[:-1] \\\n",
    "#            for i in avg_tuple for j, k in [('Inc', 'CaseIncLoss'), ('Pd', 'PaidLoss')]}, \\\n",
    "#         }, \\\n",
    "#         index=pd.Index(range(1,10), name='Lag')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = comp.groupby(level=['GRName', 'Line']).apply(make_links)\n",
    "links.index.names = ['GRName', 'Line', 'Kind', 'Method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.xs(sfm, level=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit comp.groupby(level=['GRName', 'Line']).apply(make_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out SFM triangles\n",
    "bit = links.loc[[sfm]].head(24)\n",
    "bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = links.iloc[0:288*2, :]\n",
    "mbit = bit.stack('Lag').reset_index()  \n",
    "mbit.rename(mapper={0: 'FTU'}, inplace=True, axis=1)\n",
    "mbit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotit(b):\n",
    "    if plotit.first: \n",
    "        sns.relplot(data=b, kind='line', x='Lag', y='FTU', hue='Kind', style='Method', \n",
    "            style_order=['wtd 10', 'wtd 5', 'wtd 3', 'str 10', 'str 5', 'str 3'], \n",
    "            col='Line', row='GRName', \n",
    "            height=5, aspect=1.3)\n",
    "    else:\n",
    "        plotit.first += 1\n",
    "plotit.first = 0 \n",
    "# need some nifty footwork because apply gets called twice first go around \n",
    "mbit.groupby('GRName').apply( plotit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bootstrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.loc[[sfm]].filter(regex=\"Paid\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = comp.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comp.index.get_level_values('AY').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1997-1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = comp.loc[[(sfm, 'Comm Auto')]]\n",
    "bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def shorten(s):\n",
    "    if len(s) < 12:\n",
    "        return s\n",
    "    else:\n",
    "        re.sub\n",
    "        s = re.sub(' (Co|Ins|Grp|Exchange|Of|Inc|of)', '', s)\n",
    "        s = s.replace('Agricultural', 'Ag').replace('Exchange', 'Ex'). replace('Associated', 'Assoc')\n",
    "    if len(s) > 12:\n",
    "        s = ' '.join([i[:4] for i in s.split(' ')][:3])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_inc_plot(df, co_name='', line_name='', bins=201, dd=True, ax=None, legend=False):\n",
    "    '''\n",
    "    bootstrap from paid and incurred and create product distribution \n",
    "    input is result of running\n",
    "    \n",
    "        links = comp.groupby(level=['GRName', 'Line']).apply(make_links)\n",
    "        links.index.names = ['GRName', 'Line', 'Kind', 'Method']\n",
    "    \n",
    "    index GRName, Line, AY, col groups for Paid, CaseInc loss and links  and lag \n",
    "    '''\n",
    "    \n",
    "    # allows use with groupby\n",
    "    if co_name == '':\n",
    "        co_name, line_name, _ = df.index[0]\n",
    "   \n",
    "    yrs = list(df.index.get_level_values('AY').unique())\n",
    "    nyrs = yrs[-1] - yrs[0]\n",
    "    \n",
    "    # piece of interest\n",
    "    bit = df.xs((co_name, line_name), level=('GRName', 'Line'))\n",
    "    \n",
    "    if len(bit) < 10:\n",
    "        return\n",
    "    \n",
    "    # make kronecker products \n",
    "    # pull off most recent year losses \n",
    "    kpi = np.array(bit.loc[yrs[-1], ('CaseIncLoss', 1)])\n",
    "    kpp = np.array(bit.loc[yrs[-1], ('PaidLoss', 1)])\n",
    "    \n",
    "    # and complete with link ratios \n",
    "    for i in range(0, nyrs):\n",
    "        kpp = np.kron(kpp, bit.loc[yrs[0]:yrs[0]+i, ('PaidLink', nyrs - i)])\n",
    "        kpi = np.kron(kpi, bit.loc[yrs[0]:yrs[0]+i, ('CaseIncLink', nyrs - i)])\n",
    "\n",
    "    ult = pd.DataFrame( {'inc' : kpi, 'pd' : kpp})\n",
    "    # stats \n",
    "    d = ult.describe().iloc[1:, :]\n",
    "    if dd:\n",
    "        display(d)\n",
    "    \n",
    "    if ax is None:\n",
    "        f = plt.figure()\n",
    "        a = f.gca()\n",
    "    else:\n",
    "        a = next(ax)\n",
    "    \n",
    "    bp = np.linspace(d.loc['min', :].min(), d.loc['max', :].max(), bins)\n",
    "    mnn = d.loc['mean', :].min()\n",
    "    mnx = d.loc['mean', :].max()\n",
    "    sd = d.loc['std', : ].max()\n",
    "    bp = np.linspace(max(0, mnn - 4*sd), mnx + 4*sd, bins)\n",
    "    npd,  _, _ = a.hist(kpp, bins=bp, color='b', alpha=0.5, label='Paid')\n",
    "    ninc, _, _ = a.hist(kpi, bins=bp, color='r', alpha=0.5, label='Incurred')\n",
    "    bay = ninc*npd / sum(ninc*npd) * sum(npd)\n",
    "    xs = (bp[1:]+bp[0:-1])/2\n",
    "    a.plot(xs, bay, '-g', label='Posterior')\n",
    "    if legend:\n",
    "        a.legend(frameon=False)\n",
    "    a.set(title='{:}/{:}\\nMLE={:,.1f}, CV(I/Pd)={:.3f}/{:.3f}'.format(shorten(co_name), line_name, xs[bay.argmax()]/1e3, \n",
    "                                                                *(d.loc['std']/d.loc['mean']) ))\n",
    "    return ult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['Comm Auto', 'PP Auto', 'Other Liab', 'Work Comp', 'Products Liab', 'Med Mal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(12,8))\n",
    "ax = iter(ax.flatten())\n",
    "for l in lines:\n",
    "    ult = pd_inc_plot(comp, sfm, l, dd=False, ax=ax, legend=(l==lines[0]))\n",
    "# tidy up \n",
    "for a in ax:\n",
    "    f.delaxes(a)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(df, line='', co='', threshold=250000):\n",
    "    '''\n",
    "    all lines for given co or all cos for given line \n",
    "    '''\n",
    "    if line=='' and co=='':\n",
    "        return \n",
    "    \n",
    "    if line != '':\n",
    "        bit = df.query(f' Line==\"{line}\" ')        \n",
    "        ncos = len(bit) / 10 \n",
    "        nr = int(ncos/6)\n",
    "        if nr < ncos/6: nr += 1\n",
    "        f, ax = plt.subplots(nr, 6, figsize=(18, 2.4*nr))\n",
    "        ax = iter(ax.flatten())\n",
    "        \n",
    "    elif co != '':\n",
    "        bit = df.query(f' GRName==\"{co}\" ')\n",
    "        f, ax = plt.subplots(2, 3, figsize=(12,6))\n",
    "        ax = iter(ax.flatten())\n",
    "    \n",
    "    g = bit.groupby(['GRName', 'Line'])\n",
    "\n",
    "    l = True\n",
    "    for k, v in g.groups.items():\n",
    "        grp = bit.loc[v]\n",
    "        if grp.CaseIncLoss.sum().sum() > threshold:\n",
    "            ult = pd_inc_plot(grp, dd=False, ax=ax, legend=l)\n",
    "            l = False\n",
    "        \n",
    "    # tidy up \n",
    "    for a in ax:\n",
    "        f.delaxes(a)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in comp.index.get_level_values('GRName').unique() if i[:5] == 'Canal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(comp, 'Comm Auto', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(comp, 'PP Auto', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(comp, 'Work Comp', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For SciKit-Learn Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CAS data\n",
    "data_url = 'https://www.casact.org/research/reserve_data'\n",
    "lobs = ['medmal','ppauto','wkcomp']\n",
    "data = pd.DataFrame()\n",
    "data = []\n",
    "columns = ['GRCODE','GRNAME','AccidentYear','DevelopmentYear','DevelopmentLag'\n",
    "           ,'IncurLoss', 'CumPaidLoss','BulkLoss','EarnedPremDIR'\n",
    "           ,'EarnedPremCeded','EarnedPremNet', 'Single','PostedReserve97']\n",
    "for lob in lobs:\n",
    "    file_url = f'{data_url}/{lob}_pos.csv'\n",
    "    subset = pd.read_csv(file_url, names=columns, skiprows=1)\n",
    "    subset['LOB'] = lob\n",
    "    data.append(subset)\n",
    "data1 = pd.concat(data)\n",
    "data = data1.query(\" DevelopmentYear <= 1997 \").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative using append\n",
    "data_url = 'https://www.casact.org/research/reserve_data'\n",
    "# Read in the data\n",
    "lobs = ['medmal','ppauto','wkcomp']\n",
    "data = pd.DataFrame()\n",
    "columns = ['GRCODE','GRNAME','AccidentYear','DevelopmentYear','DevelopmentLag'\n",
    "           ,'IncurLoss', 'CumPaidLoss','BulkLoss','EarnedPremDIR'\n",
    "           ,'EarnedPremCeded','EarnedPremNet', 'Single','PostedReserve97']\n",
    "for lob in lobs:\n",
    "    file_url = f'{data_url}/{lob}_pos.csv'\n",
    "    subset = pd.read_csv(file_url, names=columns, skiprows=1)\n",
    "    subset['LOB'] = lob\n",
    "    data = data.append(subset, sort=True)\n",
    "data = data[data['DevelopmentYear']<=1997].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "def make_trg(data):\n",
    "    # Find largest 20 companies by premium size for each LOB\n",
    "    aggregates = (data[data['DevelopmentYear']==1997].groupby(['LOB','GRNAME']) \\\n",
    "                                                 .sum()['IncurLoss']) \\\n",
    "                                                 .reset_index()\n",
    "    top_20_by_lob = aggregates.iloc[aggregates.groupby('LOB')['IncurLoss'] \\\n",
    "                              .nlargest(19).index.levels[1]]\n",
    "    data2 = data.merge(top_20_by_lob, how='left', on=['LOB','GRNAME'])\n",
    "    data2.loc[data2.iloc[:,-1].isna(),'GRNAME'] = 'Other'\n",
    "    \n",
    "    # Create Triangles\n",
    "    triangles = pd.pivot_table(data2, index=['GRNAME','LOB','AccidentYear'],\n",
    "                               columns='DevelopmentLag', values='CumPaidLoss',\n",
    "                               aggfunc='sum')\n",
    "    \n",
    "    # Determine LDF Weights\n",
    "    weight = np.array(~triangles.iloc[:,1:].isna())\n",
    "    columns = [f'{triangles.columns[num]}-{triangles.columns[num+1]}'\n",
    "               for num, item in enumerate(triangles.columns[:-1])]\n",
    "\n",
    "    # Volume-weighted numerator and demoninator\n",
    "    numerator = (\n",
    "        (triangles.iloc[:,1:]).reset_index() \n",
    "                                     .drop('AccidentYear',axis=1)\n",
    "                                     .groupby(['GRNAME','LOB'])\n",
    "                                     .sum(axis=0))\n",
    "    denominator = (\n",
    "        (weight*triangles.iloc[:,:-1]).reset_index()\n",
    "                                      .drop('AccidentYear',axis=1)\n",
    "                                      .groupby(['GRNAME','LOB'])\n",
    "                                      .sum(axis=0))\n",
    "    numerator.columns = denominator.columns = columns\n",
    "\n",
    "    # Development Patterns\n",
    "    ldf = (numerator/denominator).fillna(1.0)\n",
    "    \n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ldf_orig = make_trg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatives, including original\n",
    "def make_trg_2(data):\n",
    "    '''\n",
    "    see _alt that this method is fastest\n",
    "    '''\n",
    "    aggregates2 = data.query(' DevelopmentYear ==  1997 ').groupby(['LOB','GRNAME'])['IncurLoss'].sum() \n",
    "    top_20_by_lob = aggregates2.groupby(level='LOB').apply(lambda x : x.nlargest(19).reset_index(level=0, drop=True))\n",
    "    \n",
    "    data_alt2 = data.merge(top_20_by_lob.to_frame(), how='left', left_on=['LOB','GRNAME'], right_index=True)\n",
    "    data_alt2.loc[data_alt2.loc[:,'IncurLoss_y'].isna(), 'GRNAME'] = 'Other'\n",
    "    \n",
    "    # create triangles \n",
    "    triangles = pd.pivot_table(data_alt2, index=['GRNAME','LOB','AccidentYear'],\n",
    "                           columns='DevelopmentLag', values='CumPaidLoss')\n",
    "    \n",
    "    # Determine LDF Weights ORIG\n",
    "    w = pd.DataFrame(np.array([[1 if i+j<9 else 0 for i in range(9)] for j in range(10)]))\n",
    "    weight = np.tile(w, (int(triangles.shape[0]/10), 1))\n",
    "    columns = [f'{triangles.columns[num]}-{triangles.columns[num+1]}'\n",
    "               for num, item in enumerate(triangles.columns[:-1])]\n",
    "\n",
    "    # Volume-weighted numerator and demoninator mask for denom only; values on num because want index from num \n",
    "    ldf = (triangles.iloc[:,1:].groupby(level=['GRNAME','LOB']).sum().values / \\\n",
    "           (weight*triangles.iloc[:,:-1]).groupby(level=['GRNAME','LOB']).sum()).fillna(1.0) \n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ldf_alt = make_trg_2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_orig = make_trg(data)\n",
    "ldf_alt = make_trg_2(data)\n",
    "np.allclose(ldf_orig, ldf_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_alt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000000  # 100 million rows \n",
    "df = pd.DataFrame({\n",
    "    'a': np.random.randn(n),\n",
    "    'b': np.random.randn(n),\n",
    "    'c': np.random.randn(n),\n",
    "})\n",
    "a =  np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = np.sin(a - 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = np.sin(df['a'] - 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = np.sin(df['a'].values - 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = 'sin(a - 1) + 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = numexpr.evaluate(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowork(a):\n",
    "    expr = 'sin(a - 1) + 1'\n",
    "    return numexpr.evaluate(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit r = dowork(df['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Intro\n",
    "\n",
    "## Function We Will Discuss\n",
    "\n",
    "* DataFrame\n",
    "* head, tail, describe, summary \n",
    "* unique\n",
    "* from csv, dictionary \n",
    "* loc, slices\n",
    "* create_index, reset_index \n",
    "* MultiIndex \n",
    "* loc, slices and xs\n",
    "* query \n",
    "* pivot, stack and unstack\n",
    "* melt\n",
    "* **concat**, append, keys \n",
    "* pivot_table (crosstab)\n",
    "* **merge** (indicator) and join\n",
    "* groupby (.groups, .get_group, as_index)\n",
    "* sum, mean, std etc. \n",
    "* aggregate\n",
    "* transform (same size as input whiten)\n",
    "* apply\n",
    "* assign \n",
    "* plot\n",
    "\n",
    "## Functions not covered but check out on your own\n",
    "* map (series), applymap (dataframes) \n",
    "* evaluate \n",
    "* str\n",
    "* dt\n",
    "* style\n",
    "\n",
    "\n",
    "# Seaborn Plotting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(5,5); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(x)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.columns = list('abcde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['class'] = list('αβββζ')\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.index.name = 'id'\n",
    "df0.columns.name = 'var'\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'class': list('vwxxy'), 'subclass': list('aaabb'), 'a': np.random.randn(5), 'c': np.arange(5, dtype=np.float)}, index=pd.Index(range(5), name='idx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( (df0, df), sort=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.select_dtypes(np.number) / df.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sinb'] = np.sin(df.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index('x')\n",
    "df1.columns.name = 'variable'\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'y': list('lmnop'), 'a': np.random.randn(5), 'b': np.arange(5, dtype=np.float)}, index=pd.Index(list('abcjk'), name='x'))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((df1,df2), sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat((df1,df2), sort=True, keys=['df1', 'df2'], names=['src'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.b.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['df1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[:, 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[:, 'a':'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3.a < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[df3.a < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[df3.a < 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.query(' a < 0 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['df1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), 'b'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), slice('b','d')), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(slice(None), 'b')], df3.loc[:, 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.xs('b', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.xs('b', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.reset_index()\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot(index='src', columns='b', values='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot(index='src', columns='b', values=['a', 'sinb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.pivot_table(index=['src', 'x'], columns='b', values=['a', 'sinb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = df3.groupby(level='x') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.get_group('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = df4.groupby('x')\n",
    "g4.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.get_group('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.agg([sum, np.std, np.min, np.max, np.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.agg({'a' : [sum, np.std, np.min, np.max, np.size], 'b': [sum, np.std] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.apply(lambda x : display(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.apply(lambda x : print(x.a * x.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = g3.get_group('c')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series( (y.a * y.b).values, name='ab', index=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.apply( lambda y : pd.Series((y.a * y.b).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.apply( lambda y : pd.DataFrame((y.a * y.b).values, index=pd.Index(range(10, 10+len(y)), name='idx'), columns=['ab']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.array([1,2,3]),np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.get_group('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.apply( lambda y : pd.DataFrame(np.hstack([y.a, y.b, (y.a * y.b).values]) ).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'x': range(10), 'a':list('abcdefghij')})\n",
    "df.assign(a = lambda x :  't' if x.a == 'g' else x.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 = 0.2, .4\n",
    "fz1 = ss.lognorm(s1, scale=np.exp(-s1**2/2))\n",
    "fz2 = ss.lognorm(s2, scale=np.exp(-s1**2/2))\n",
    "xs = np.linspace(0,10, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0,10, 101)\n",
    "x1, x2 = np.meshgrid(xs, xs)\n",
    "z = fz1.cdf(x1) * fz2.cdf(x2)\n",
    "\n",
    "plt.imshow(z, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 if True else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit(s1, s2, x_list, biv_den=True):\n",
    "    '''\n",
    "    s1, s2 = sigmas of lognormals of mean 1 \n",
    "    x = line to plot\n",
    "    '''\n",
    "    \n",
    "    fz1 = ss.lognorm(s1, scale=np.exp(-s1**2/2))\n",
    "    fz2 = ss.lognorm(s2, scale=np.exp(-s1**2/2))\n",
    "    xs = np.linspace(0,10, 101)\n",
    "    ts = np.linspace(0,1,101)\n",
    "    \n",
    "    n_plots = 4 if biv_den else 2\n",
    "    plot_w = 10 if biv_den else 2\n",
    "    plt.figure(figsize=(plot_w, 2.4))\n",
    "    plt.subplot(1,n_plots,1)\n",
    "    \n",
    "    for x in x_list:\n",
    "        y1 = fz1.cdf(ts * x)\n",
    "        y2 = fz2.cdf((1 - ts) * x)\n",
    "        plt.plot(y1, y2)\n",
    "\n",
    "    plt.subplot(1,n_plots,2)\n",
    "    for x in x_list: \n",
    "        y1 = fz1.pdf(ts * x)\n",
    "        y2 = fz2.pdf((1 - ts) * x)\n",
    "        plt.plot(ts, y1, label='1')\n",
    "        plt.plot(ts, y2, label='2')\n",
    "        plt.plot(ts, y2/y1, label='2/1')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim(0, 10)\n",
    "\n",
    "    if biv_den:\n",
    "        plt.subplot(1,n_plots,3)\n",
    "        # bivariate density \n",
    "        x1, x2 = np.meshgrid(xs, xs)\n",
    "        z = fz1.pdf(x1) * fz2.pdf(x2)\n",
    "        plt.imshow(np.log(z), origin='lower', extent=[0,10,0,10])\n",
    "#         plt.xlim(0, xs[-1])\n",
    "#         plt.ylim(0, xs[-1])\n",
    "        plt.colorbar();\n",
    "\n",
    "        plt.subplot(1,n_plots,4)\n",
    "        # bivariate density \n",
    "        x1, x2 = np.meshgrid(ts, ts)\n",
    "        z = fz1.pdf(fz1.isf(1-x1)) * fz2.pdf(fz2.isf(1-x2))\n",
    "        plt.imshow(np.log(z), origin='lower', extent=[0,1,0,1])\n",
    "#         plt.xlim(0, xs[-1])\n",
    "#         plt.ylim(0, xs[-1])\n",
    "        plt.colorbar();\n",
    "\n",
    "    plt.suptitle(f'$\\sigma_1={s1}, \\sigma_2={s2}, x={x}$')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1, s2 in zip((.3, .3, 5), (.3, 2, 5)):\n",
    "    pit(s1, s2, [4.], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1, s2 in zip((.3, .3, 1, 1, 3, 3), (.3, .5, 1, 2, 3, 5)):\n",
    "    pit(s1, s2, [1.], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
